{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.23 (you have 1.4.13). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([245, 1024])\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from honeybee.loaders import Slide\n",
    "from honeybee.models import UNI, TissueDetector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "\n",
    "slide = Slide(\n",
    "    slide_image_path=\"/mnt/f/Projects/HoneyBee/tmp/sample_wsi.svs\",\n",
    "    tileSize=256,\n",
    "    max_patches=1_000,\n",
    "    visualize=False,\n",
    "    tissue_detector=TissueDetector(model_path=\"/mnt/d/Models/TissueDetector/HnE.pt\"),\n",
    ")\n",
    "patches = slide.load_patches_concurrently(target_patch_size=224)\n",
    "\n",
    "uni = UNI(model_path=\"/mnt/d/Models/UNI/pytorch_model.bin\")\n",
    "embedding = uni.load_model_and_predict(patches=patches)\n",
    "print(embedding.shape)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aakash/miniconda3/envs/honeybee/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "embedding_np = embedding.cpu().numpy() if isinstance(embedding, torch.Tensor) else embedding\n",
    "patch_coords = slide.get_patch_coords()\n",
    "\n",
    "# map the embeddings_3d to RGB values for visualization and then visualize it on top of the slide\n",
    "def umap_reducer(x: np.ndarray, dims: int = 3, nns: int = 10) -> np.ndarray:\n",
    "    \"\"\"UMAP reduction of the input data.\"\"\"\n",
    "    reducer = UMAP(\n",
    "        n_neighbors=nns,\n",
    "        n_components=dims,\n",
    "        metric=\"manhattan\",\n",
    "        spread=0.5,\n",
    "        random_state=2,\n",
    "    )\n",
    "    reduced = reducer.fit_transform(x)\n",
    "    reduced -= reduced.min(axis=0)\n",
    "    reduced /= reduced.max(axis=0)\n",
    "    return reduced\n",
    "\n",
    "rgb_values = umap_reducer(embedding_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape: (245, 1024)\n",
      "RGB values shape: (245, 3)\n",
      "Patch coords shape: (414, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"embedding shape:\", embedding_np.shape)\n",
    "print(\"RGB values shape:\", rgb_values.shape)\n",
    "print(\"Patch coords shape:\", patch_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honeybee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
