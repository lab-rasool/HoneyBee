{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical embeddings array shape: (11428, 1024)\n",
      "WSI embeddings array shape: (456387, 1024)\n",
      "Original PatientID: TCGA-KN-8430, Original Patient Project: TCGA-KICH, Random Patient Index: 10492, Random Patch Index: 6\n",
      "Similar PatientIDs and their Project IDs:\n",
      "PatientID: TCGA-KN-8430, ProjectID: TCGA-KICH\n",
      "PatientID: TCGA-RY-A83Z, ProjectID: TCGA-LGG\n",
      "PatientID: TCGA-E2-A9RU, ProjectID: TCGA-BRCA\n",
      "PatientID: TCGA-LQ-A4E4, ProjectID: TCGA-BRCA\n",
      "PatientID: TCGA-ZJ-AAX4, ProjectID: TCGA-CESC\n",
      "PatientID: TCGA-C8-A131, ProjectID: TCGA-BRCA\n",
      "PatientID: TCGA-B0-4707, ProjectID: TCGA-KIRC\n",
      "PatientID: TCGA-CV-A45Y, ProjectID: TCGA-HNSC\n",
      "PatientID: TCGA-12-3649, ProjectID: TCGA-GBM\n",
      "PatientID: TCGA-CV-5443, ProjectID: TCGA-HNSC\n",
      "Distances to similar items: [[0.         0.03129907 0.03277805 0.03298555 0.03298659 0.03384599\n",
      "  0.03439792 0.03646088 0.03675169 0.03732942]]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import faiss\n",
    "import random\n",
    "\n",
    "\n",
    "# Function to perform similarity search\n",
    "def search(query_embedding, index, k=10):\n",
    "    query_embedding = np.array(query_embedding, dtype=np.float32).reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    return distances, indices\n",
    "\n",
    "\n",
    "# Load the clinical dataset\n",
    "clinical_dataset = load_dataset(\"Lab-Rasool/TCGA\", \"clinical\", split=\"gatortron\")\n",
    "clinical_embeddings = []\n",
    "for item in clinical_dataset:\n",
    "    embedding = np.frombuffer(item.get(\"embedding\"), dtype=np.float32).reshape(\n",
    "        item.get(\"embedding_shape\")\n",
    "    )\n",
    "    clinical_embeddings.append(embedding.flatten())\n",
    "clinical_embeddings_array = np.vstack(clinical_embeddings)\n",
    "print(f\"Clinical embeddings array shape: {clinical_embeddings_array.shape}\")\n",
    "# Build the FAISS index for the clinical embeddings\n",
    "dimension = clinical_embeddings_array.shape[1]\n",
    "index_clinical = faiss.IndexFlatL2(dimension)  # Using L2 distance\n",
    "index_clinical.add(clinical_embeddings_array)\n",
    "\n",
    "# Load the WSI dataset\n",
    "wsi_dataset = load_dataset(\"Lab-Rasool/TCGA\", \"wsi\", split=\"uni\")\n",
    "# Extract and concatenate all patch embeddings into a single array\n",
    "wsi_all_embeddings = []\n",
    "wsi_patient_ids = []\n",
    "wsi_indices = []\n",
    "for i, item in enumerate(wsi_dataset):\n",
    "    embedding = np.frombuffer(item.get(\"embedding\"), dtype=np.float32).reshape(\n",
    "        item.get(\"embedding_shape\")\n",
    "    )\n",
    "    num_patches = embedding.shape[0]\n",
    "    wsi_all_embeddings.extend(embedding)\n",
    "    wsi_patient_ids.extend([item[\"PatientID\"]] * num_patches)\n",
    "    wsi_indices.extend([(i, j) for j in range(num_patches)])\n",
    "wsi_all_embeddings_array = np.vstack(wsi_all_embeddings)\n",
    "print(f\"WSI embeddings array shape: {wsi_all_embeddings_array.shape}\")\n",
    "# Build the FAISS index for the WSI embeddings\n",
    "index_wsi = faiss.IndexFlatL2(dimension)  # Using L2 distance\n",
    "index_wsi.add(wsi_all_embeddings_array)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Randomly pick one patch embedding from a random patient in the WSI dataset\n",
    "random_patient_index = random.randint(0, len(wsi_dataset) - 1)\n",
    "random_patch_index = random.randint(\n",
    "    0, wsi_dataset[random_patient_index][\"embedding_shape\"][0] - 1\n",
    ")\n",
    "query_embedding = wsi_all_embeddings_array[\n",
    "    wsi_indices.index((random_patient_index, random_patch_index))\n",
    "]\n",
    "\n",
    "# Perform similarity search on WSI embeddings\n",
    "distances, indices = search(query_embedding, index_wsi, k=10)\n",
    "\n",
    "# Get the PatientIDs of the original query embedding and the similar embeddings\n",
    "original_patient_id = wsi_patient_ids[\n",
    "    wsi_indices.index((random_patient_index, random_patch_index))\n",
    "]\n",
    "\n",
    "# original_patient_project\n",
    "original_patient_project = None\n",
    "for clinical_item in clinical_dataset:\n",
    "    if clinical_item[\"case_submitter_id\"] == original_patient_id:\n",
    "        original_patient_project = clinical_item[\"project_id\"]\n",
    "        break\n",
    "if original_patient_project is None:\n",
    "    print(f\"Project ID not found for PatientID: {original_patient_id}\")\n",
    "\n",
    "print(\n",
    "    f\"Original PatientID: {original_patient_id}, Original Patient Project: {original_patient_project}, Random Patient Index: {random_patient_index}, Random Patch Index: {random_patch_index}\"\n",
    ")\n",
    "similar_patient_ids = [wsi_patient_ids[idx] for idx in indices[0]]\n",
    "\n",
    "# Find the corresponding project IDs from the clinical dataset\n",
    "project_ids = []\n",
    "for patient_id in similar_patient_ids:\n",
    "    for clinical_item in clinical_dataset:\n",
    "        if clinical_item[\"case_submitter_id\"] == patient_id:\n",
    "            project_ids.append(clinical_item[\"project_id\"])\n",
    "            break\n",
    "\n",
    "print(\"Similar PatientIDs and their Project IDs:\")\n",
    "for patient_id, project_id in zip(similar_patient_ids, project_ids):\n",
    "    print(f\"PatientID: {patient_id}, ProjectID: {project_id}\")\n",
    "print(f\"Distances to similar items: {distances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HoneyBee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
