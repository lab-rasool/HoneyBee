{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap.umap_ as umap\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Constants\n",
    "OUTPUT_DIR = \"multimodal_analysis_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Selected cancer types\n",
    "TARGET_CANCER_TYPES = ['TCGA-KIRC', 'TCGA-OV', 'TCGA-BRCA']\n",
    "\n",
    "def get_id_column(df):\n",
    "    \"\"\"\n",
    "    Determine the appropriate ID column in a dataframe.\n",
    "    Check for common patient ID column names and return the first one found.\n",
    "    \"\"\"\n",
    "    possible_id_columns = ['case_submitter_id', 'PatientID', 'patient_id', 'ID']\n",
    "    \n",
    "    for col in possible_id_columns:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    \n",
    "    # If no known ID column is found, print all columns and raise an error\n",
    "    print(f\"Available columns: {df.columns.tolist()}\")\n",
    "    raise ValueError(\"No patient ID column found in dataframe.\")\n",
    "\n",
    "def process_clinical_embeddings():\n",
    "    \"\"\"\n",
    "    Process clinical embeddings using the embedding_shape field if available\n",
    "    \"\"\"\n",
    "    print(\"Loading clinical data...\")\n",
    "    clinical_data = load_dataset(\"Lab-Rasool/TCGA\", \"clinical\", split=\"gatortron\").to_pandas()\n",
    "    print(f\"Loaded {len(clinical_data)} total clinical samples\")\n",
    "    \n",
    "    # Filter by cancer type\n",
    "    if 'project_id' in clinical_data.columns:\n",
    "        clinical_data = clinical_data[clinical_data['project_id'].isin(TARGET_CANCER_TYPES)]\n",
    "        print(f\"After filtering for {TARGET_CANCER_TYPES}, found {len(clinical_data)} clinical samples\")\n",
    "    \n",
    "    # Remove rows with null embeddings\n",
    "    clinical_data = clinical_data.dropna(subset=[\"embedding\"])\n",
    "    print(f\"After removing null embeddings, {len(clinical_data)} clinical samples remain\")\n",
    "    \n",
    "    # Get ID column\n",
    "    clinical_id_col = get_id_column(clinical_data)\n",
    "    \n",
    "    # Process embeddings\n",
    "    processed_embeddings = []\n",
    "    \n",
    "    if \"embedding_shape\" in clinical_data.columns:\n",
    "        print(\"Using embedding_shape for clinical embeddings\")\n",
    "        for idx, row in tqdm(clinical_data.iterrows(), desc=\"Processing clinical embeddings\", total=len(clinical_data)):\n",
    "            try:\n",
    "                emb = np.frombuffer(row[\"embedding\"], dtype=np.float32)\n",
    "                shape = row[\"embedding_shape\"]\n",
    "                reshaped_emb = emb.reshape(shape)\n",
    "                processed_embeddings.append(reshaped_emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing clinical embedding at index {idx}: {e}\")\n",
    "                # Try to find a valid embedding to determine shape\n",
    "                if len(processed_embeddings) > 0:\n",
    "                    processed_embeddings.append(np.zeros_like(processed_embeddings[0]))\n",
    "                else:\n",
    "                    processed_embeddings.append(np.zeros(1024, dtype=np.float32))\n",
    "    else:\n",
    "        print(\"No embedding_shape for clinical embeddings, using raw buffers\")\n",
    "        for idx, row in tqdm(clinical_data.iterrows(), desc=\"Processing clinical embeddings\", total=len(clinical_data)):\n",
    "            try:\n",
    "                emb = np.frombuffer(row[\"embedding\"], dtype=np.float32)\n",
    "                processed_embeddings.append(emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing clinical embedding at index {idx}: {e}\")\n",
    "                if len(processed_embeddings) > 0:\n",
    "                    processed_embeddings.append(np.zeros_like(processed_embeddings[0]))\n",
    "                else:\n",
    "                    processed_embeddings.append(np.zeros(1024, dtype=np.float32))\n",
    "    \n",
    "    # Create DataFrame with patient IDs and embeddings\n",
    "    clinical_df = pd.DataFrame({\n",
    "        'patient_id': clinical_data[clinical_id_col],\n",
    "        'cancer_type': clinical_data['project_id'],\n",
    "        'modality': 'clinical'\n",
    "    })\n",
    "    clinical_df['embeddings'] = processed_embeddings\n",
    "    \n",
    "    return clinical_df\n",
    "\n",
    "def process_pathology_embeddings(target_patient_ids=None):\n",
    "    \"\"\"\n",
    "    Process pathology embeddings using the embedding_shape field if available\n",
    "    \"\"\"\n",
    "    print(\"Loading pathology report data...\")\n",
    "    pathology_data = load_dataset(\"Lab-Rasool/TCGA\", \"pathology_report\", split=\"gatortron\").to_pandas()\n",
    "    print(f\"Loaded {len(pathology_data)} total pathology samples\")\n",
    "    \n",
    "    # Get ID column\n",
    "    pathology_id_col = get_id_column(pathology_data)\n",
    "    \n",
    "    # Filter by patient IDs if provided\n",
    "    if target_patient_ids:\n",
    "        original_count = len(pathology_data)\n",
    "        pathology_data = pathology_data[pathology_data[pathology_id_col].isin(target_patient_ids)]\n",
    "        print(f\"After filtering by patient IDs, found {len(pathology_data)} pathology samples out of {original_count}\")\n",
    "    \n",
    "    # Remove rows with null embeddings\n",
    "    pathology_data = pathology_data.dropna(subset=[\"embedding\"])\n",
    "    print(f\"After removing null embeddings, {len(pathology_data)} pathology samples remain\")\n",
    "    \n",
    "    # Process embeddings\n",
    "    processed_embeddings = []\n",
    "    \n",
    "    if \"embedding_shape\" in pathology_data.columns:\n",
    "        print(\"Using embedding_shape for pathology embeddings\")\n",
    "        for idx, row in tqdm(pathology_data.iterrows(), desc=\"Processing pathology embeddings\", total=len(pathology_data)):\n",
    "            try:\n",
    "                emb = np.frombuffer(row[\"embedding\"], dtype=np.float32)\n",
    "                shape = row[\"embedding_shape\"]\n",
    "                reshaped_emb = emb.reshape(shape)\n",
    "                processed_embeddings.append(reshaped_emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing pathology embedding at index {idx}: {e}\")\n",
    "                if len(processed_embeddings) > 0:\n",
    "                    processed_embeddings.append(np.zeros_like(processed_embeddings[0]))\n",
    "                else:\n",
    "                    processed_embeddings.append(np.zeros(1024, dtype=np.float32))\n",
    "    else:\n",
    "        print(\"No embedding_shape for pathology embeddings, using raw buffers\")\n",
    "        for idx, row in tqdm(pathology_data.iterrows(), desc=\"Processing pathology embeddings\", total=len(pathology_data)):\n",
    "            try:\n",
    "                emb = np.frombuffer(row[\"embedding\"], dtype=np.float32)\n",
    "                processed_embeddings.append(emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing pathology embedding at index {idx}: {e}\")\n",
    "                if len(processed_embeddings) > 0:\n",
    "                    processed_embeddings.append(np.zeros_like(processed_embeddings[0]))\n",
    "                else:\n",
    "                    processed_embeddings.append(np.zeros(1024, dtype=np.float32))\n",
    "    \n",
    "    # Create DataFrame with patient IDs and embeddings\n",
    "    pathology_df = pd.DataFrame({\n",
    "        'patient_id': pathology_data[pathology_id_col],\n",
    "        'modality': 'pathology_report'\n",
    "    })\n",
    "    pathology_df['embeddings'] = processed_embeddings\n",
    "    \n",
    "    return pathology_df\n",
    "\n",
    "def process_radiology_embeddings(target_patient_ids=None):\n",
    "    \"\"\"\n",
    "    Process radiology embeddings using the embedding_shape field to correctly reshape data\n",
    "    \"\"\"\n",
    "    print(\"Loading radiology data...\")\n",
    "    radiology_data = load_dataset(\"Lab-Rasool/TCGA\", \"radiology\", split=\"radimagenet\").to_pandas()\n",
    "    print(f\"Loaded {len(radiology_data)} total radiology samples\")\n",
    "    \n",
    "    # Get ID column\n",
    "    radiology_id_col = get_id_column(radiology_data)\n",
    "    \n",
    "    # Filter by patient IDs if provided\n",
    "    if target_patient_ids:\n",
    "        original_count = len(radiology_data)\n",
    "        radiology_data = radiology_data[radiology_data[radiology_id_col].isin(target_patient_ids)]\n",
    "        print(f\"After filtering by patient IDs, found {len(radiology_data)} radiology samples out of {original_count}\")\n",
    "    \n",
    "    # Remove rows with null embeddings\n",
    "    radiology_data = radiology_data.dropna(subset=[\"embedding\"])\n",
    "    print(f\"After removing null embeddings, {len(radiology_data)} radiology samples remain\")\n",
    "    \n",
    "    # Process embeddings\n",
    "    processed_embeddings = []\n",
    "    \n",
    "    if \"embedding_shape\" in radiology_data.columns:\n",
    "        print(\"Using embedding_shape for radiology embeddings\")\n",
    "        for idx, row in tqdm(radiology_data.iterrows(), desc=\"Processing radiology embeddings\", total=len(radiology_data)):\n",
    "            try:\n",
    "                emb = np.frombuffer(row[\"embedding\"], dtype=np.float32)\n",
    "                shape = row[\"embedding_shape\"]\n",
    "                \n",
    "                # Sometimes embedding_shape is a string, check and convert if needed\n",
    "                if isinstance(shape, str):\n",
    "                    shape = eval(shape)  # Convert string to tuple\n",
    "                \n",
    "                reshaped_emb = emb.reshape(shape)\n",
    "                \n",
    "                # If multi-dimensional, flatten to 1D for consistency\n",
    "                if len(reshaped_emb.shape) > 1:\n",
    "                    # Take mean along all dimensions except the last\n",
    "                    flattened_emb = np.mean(reshaped_emb, axis=tuple(range(len(reshaped_emb.shape)-1)))\n",
    "                else:\n",
    "                    flattened_emb = reshaped_emb\n",
    "                \n",
    "                processed_embeddings.append(flattened_emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing radiology embedding at index {idx}: {e}\")\n",
    "                if len(processed_embeddings) > 0:\n",
    "                    processed_embeddings.append(np.zeros_like(processed_embeddings[0]))\n",
    "                else:\n",
    "                    processed_embeddings.append(np.zeros(1000, dtype=np.float32))\n",
    "    else:\n",
    "        print(\"No embedding_shape for radiology embeddings, using raw buffers\")\n",
    "        for idx, row in tqdm(radiology_data.iterrows(), desc=\"Processing radiology embeddings\", total=len(radiology_data)):\n",
    "            try:\n",
    "                # Check if embedding is a list\n",
    "                if isinstance(row[\"embedding\"], list):\n",
    "                    # Process list of embeddings\n",
    "                    slice_embs = []\n",
    "                    for e in row[\"embedding\"]:\n",
    "                        if e is not None:\n",
    "                            slice_embs.append(np.frombuffer(e, dtype=np.float32))\n",
    "                    \n",
    "                    if slice_embs:\n",
    "                        # Average embeddings\n",
    "                        avg_emb = np.mean(slice_embs, axis=0)\n",
    "                        processed_embeddings.append(avg_emb)\n",
    "                    else:\n",
    "                        # Default empty embedding\n",
    "                        processed_embeddings.append(np.zeros(1000, dtype=np.float32))\n",
    "                else:\n",
    "                    # Process single embedding\n",
    "                    emb = np.frombuffer(row[\"embedding\"], dtype=np.float32)\n",
    "                    processed_embeddings.append(emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing radiology embedding at index {idx}: {e}\")\n",
    "                if len(processed_embeddings) > 0:\n",
    "                    processed_embeddings.append(np.zeros_like(processed_embeddings[0]))\n",
    "                else:\n",
    "                    processed_embeddings.append(np.zeros(1000, dtype=np.float32))\n",
    "    \n",
    "    # Ensure all embeddings have the same length\n",
    "    lengths = [len(emb) for emb in processed_embeddings]\n",
    "    unique_lengths = set(lengths)\n",
    "    \n",
    "    if len(unique_lengths) > 1:\n",
    "        print(f\"Found {len(unique_lengths)} different embedding lengths: {unique_lengths}\")\n",
    "        # Standardize to the most common length\n",
    "        length_counts = Counter(lengths)\n",
    "        most_common_length = length_counts.most_common(1)[0][0]\n",
    "        print(f\"Standardizing all embeddings to length {most_common_length}\")\n",
    "        \n",
    "        standardized_embeddings = []\n",
    "        for emb in processed_embeddings:\n",
    "            if len(emb) < most_common_length:\n",
    "                # Pad with zeros\n",
    "                padded = np.zeros(most_common_length, dtype=np.float32)\n",
    "                padded[:len(emb)] = emb\n",
    "                standardized_embeddings.append(padded)\n",
    "            else:\n",
    "                # Truncate\n",
    "                standardized_embeddings.append(emb[:most_common_length])\n",
    "        \n",
    "        processed_embeddings = standardized_embeddings\n",
    "    \n",
    "    # Create DataFrame with patient IDs and embeddings\n",
    "    radiology_df = pd.DataFrame({\n",
    "        'patient_id': radiology_data[radiology_id_col],\n",
    "        'modality': 'radiology'\n",
    "    })\n",
    "    \n",
    "    # Add cancer_type if available\n",
    "    if 'project_id' in radiology_data.columns:\n",
    "        radiology_df['cancer_type'] = radiology_data['project_id']\n",
    "    \n",
    "    radiology_df['embeddings'] = processed_embeddings\n",
    "    \n",
    "    return radiology_df\n",
    "\n",
    "def process_molecular_embeddings(target_patient_ids=None):\n",
    "    \"\"\"\n",
    "    Process molecular embeddings using the embedding_shape field if available\n",
    "    \"\"\"\n",
    "    print(\"Loading molecular data...\")\n",
    "    molecular_data = load_dataset(\"Lab-Rasool/TCGA\", \"molecular\", split=\"senmo\").to_pandas()\n",
    "    print(f\"Loaded {len(molecular_data)} total molecular samples\")\n",
    "    print(f\"Molecular data columns: {molecular_data.columns.tolist()}\")\n",
    "    \n",
    "    # Get ID column\n",
    "    molecular_id_col = get_id_column(molecular_data)\n",
    "    \n",
    "    # Filter by patient IDs if provided\n",
    "    if target_patient_ids:\n",
    "        original_count = len(molecular_data)\n",
    "        molecular_data = molecular_data[molecular_data[molecular_id_col].isin(target_patient_ids)]\n",
    "        print(f\"After filtering by patient IDs, found {len(molecular_data)} molecular samples out of {original_count}\")\n",
    "    \n",
    "    # Determine embedding column\n",
    "    if \"embedding\" in molecular_data.columns:\n",
    "        embedding_col = \"embedding\"\n",
    "    elif \"Embeddings\" in molecular_data.columns:\n",
    "        embedding_col = \"Embeddings\"\n",
    "    else:\n",
    "        # Try to find a column with 'embed' in the name\n",
    "        embed_cols = [col for col in molecular_data.columns if 'embed' in col.lower()]\n",
    "        if embed_cols:\n",
    "            embedding_col = embed_cols[0]\n",
    "            print(f\"Using {embedding_col} for molecular embeddings\")\n",
    "        else:\n",
    "            print(\"No embedding column found in molecular data\")\n",
    "            return pd.DataFrame(columns=['patient_id', 'modality', 'cancer_type', 'embeddings'])\n",
    "    \n",
    "    # Remove rows with null embeddings\n",
    "    molecular_data = molecular_data.dropna(subset=[embedding_col])\n",
    "    print(f\"After removing null embeddings, {len(molecular_data)} molecular samples remain\")\n",
    "    \n",
    "    # Process embeddings\n",
    "    processed_embeddings = []\n",
    "    \n",
    "    if \"embedding_shape\" in molecular_data.columns:\n",
    "        print(\"Using embedding_shape for molecular embeddings\")\n",
    "        for idx, row in tqdm(molecular_data.iterrows(), desc=\"Processing molecular embeddings\", total=len(molecular_data)):\n",
    "            try:\n",
    "                emb = np.frombuffer(row[embedding_col], dtype=np.float32)\n",
    "                shape = row[\"embedding_shape\"]\n",
    "                reshaped_emb = emb.reshape(shape)\n",
    "                processed_embeddings.append(reshaped_emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing molecular embedding at index {idx}: {e}\")\n",
    "                if len(processed_embeddings) > 0:\n",
    "                    processed_embeddings.append(np.zeros_like(processed_embeddings[0]))\n",
    "                else:\n",
    "                    processed_embeddings.append(np.zeros(48, dtype=np.float32))\n",
    "    else:\n",
    "        print(\"No embedding_shape for molecular embeddings, using raw buffers\")\n",
    "        for idx, row in tqdm(molecular_data.iterrows(), desc=\"Processing molecular embeddings\", total=len(molecular_data)):\n",
    "            try:\n",
    "                emb = np.frombuffer(row[embedding_col], dtype=np.float32)\n",
    "                processed_embeddings.append(emb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing molecular embedding at index {idx}: {e}\")\n",
    "                if len(processed_embeddings) > 0:\n",
    "                    processed_embeddings.append(np.zeros_like(processed_embeddings[0]))\n",
    "                else:\n",
    "                    processed_embeddings.append(np.zeros(48, dtype=np.float32))\n",
    "    \n",
    "    # Create DataFrame with patient IDs and embeddings\n",
    "    molecular_df = pd.DataFrame({\n",
    "        'patient_id': molecular_data[molecular_id_col],\n",
    "        'modality': 'molecular'\n",
    "    })\n",
    "    \n",
    "    # Add cancer_type if available\n",
    "    if 'project_id' in molecular_data.columns:\n",
    "        molecular_df['cancer_type'] = molecular_data['project_id']\n",
    "    \n",
    "    molecular_df['embeddings'] = processed_embeddings\n",
    "    \n",
    "    return molecular_df\n",
    "\n",
    "def load_multimodal_data():\n",
    "    \"\"\"\n",
    "    Load and process embeddings from all modalities\n",
    "    \"\"\"\n",
    "    # Process clinical data first\n",
    "    clinical_df = process_clinical_embeddings()\n",
    "    \n",
    "    # Get patient IDs from clinical data to filter other modalities\n",
    "    target_patient_ids = set(clinical_df['patient_id'])\n",
    "    print(f\"Found {len(target_patient_ids)} unique patients in clinical data\")\n",
    "    \n",
    "    # Process other modalities with patient ID filtering\n",
    "    pathology_df = process_pathology_embeddings(target_patient_ids)\n",
    "    radiology_df = process_radiology_embeddings(target_patient_ids)\n",
    "    molecular_df = process_molecular_embeddings(target_patient_ids)\n",
    "    \n",
    "    # Add cancer type to modalities that don't have it\n",
    "    # Get mapping from clinical data\n",
    "    patient_to_cancer = dict(zip(clinical_df['patient_id'], clinical_df['cancer_type']))\n",
    "    \n",
    "    # Update pathology cancer type\n",
    "    if 'cancer_type' not in pathology_df.columns:\n",
    "        pathology_df['cancer_type'] = pathology_df['patient_id'].map(\n",
    "            lambda x: patient_to_cancer.get(x, TARGET_CANCER_TYPES[0])\n",
    "        )\n",
    "    \n",
    "    # Update radiology cancer type if needed\n",
    "    if 'cancer_type' not in radiology_df.columns:\n",
    "        radiology_df['cancer_type'] = radiology_df['patient_id'].map(\n",
    "            lambda x: patient_to_cancer.get(x, TARGET_CANCER_TYPES[0])\n",
    "        )\n",
    "    \n",
    "    # Update molecular cancer type if needed\n",
    "    if 'cancer_type' not in molecular_df.columns:\n",
    "        molecular_df['cancer_type'] = molecular_df['patient_id'].map(\n",
    "            lambda x: patient_to_cancer.get(x, TARGET_CANCER_TYPES[0])\n",
    "        )\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nFinal summary:\")\n",
    "    print(f\"Clinical data: {len(clinical_df)} samples\")\n",
    "    print(f\"Pathology data: {len(pathology_df)} samples\")\n",
    "    print(f\"Radiology data: {len(radiology_df)} samples\")\n",
    "    print(f\"Molecular data: {len(molecular_df)} samples\")\n",
    "    \n",
    "    return clinical_df, pathology_df, radiology_df, molecular_df\n",
    "\n",
    "def align_patient_data(clinical_df, pathology_df, radiology_df, molecular_df):\n",
    "    \"\"\"\n",
    "    Find patients that have data in all or multiple modalities and align their data\n",
    "    \"\"\"\n",
    "    print(\"Aligning patient data across modalities...\")\n",
    "    \n",
    "    # Find common patients across modalities\n",
    "    clinical_patients = set(clinical_df['patient_id'])\n",
    "    pathology_patients = set(pathology_df['patient_id'])\n",
    "    radiology_patients = set(radiology_df['patient_id'])\n",
    "    molecular_patients = set(molecular_df['patient_id'])\n",
    "    \n",
    "    print(f\"Clinical patients: {len(clinical_patients)}\")\n",
    "    print(f\"Pathology patients: {len(pathology_patients)}\")\n",
    "    print(f\"Radiology patients: {len(radiology_patients)}\")\n",
    "    print(f\"Molecular patients: {len(molecular_patients)}\")\n",
    "    \n",
    "    # Find patients with data in multiple modalities\n",
    "    print(f\"Patients in clinical and pathology: {len(clinical_patients & pathology_patients)}\")\n",
    "    print(f\"Patients in clinical and radiology: {len(clinical_patients & radiology_patients)}\")\n",
    "    print(f\"Patients in clinical and molecular: {len(clinical_patients & molecular_patients)}\")\n",
    "    \n",
    "    # Find patients with data in all modalities\n",
    "    all_modalities = clinical_patients & pathology_patients & radiology_patients & molecular_patients\n",
    "    print(f\"Found {len(all_modalities)} patients with data in all four modalities\")\n",
    "    \n",
    "    # Choose patients for analysis\n",
    "    if len(all_modalities) >= 50:  # If we have enough patients with all modalities\n",
    "        print(f\"Using {len(all_modalities)} patients with data in all modalities\")\n",
    "        common_patients = all_modalities\n",
    "    else:\n",
    "        # Find patients with data in at least 3 modalities\n",
    "        at_least_three = (\n",
    "            (clinical_patients & pathology_patients & radiology_patients) | \n",
    "            (clinical_patients & pathology_patients & molecular_patients) |\n",
    "            (clinical_patients & radiology_patients & molecular_patients)\n",
    "        )\n",
    "        \n",
    "        if len(at_least_three) >= 50:\n",
    "            print(f\"Using {len(at_least_three)} patients with data in at least 3 modalities\")\n",
    "            common_patients = at_least_three\n",
    "        else:\n",
    "            # Use patients with clinical data + at least one other modality\n",
    "            clinical_plus = (\n",
    "                (clinical_patients & pathology_patients) |\n",
    "                (clinical_patients & radiology_patients) |\n",
    "                (clinical_patients & molecular_patients)\n",
    "            )\n",
    "            \n",
    "            if len(clinical_plus) >= 50:\n",
    "                print(f\"Using {len(clinical_plus)} patients with clinical data + at least one other modality\")\n",
    "                common_patients = clinical_plus\n",
    "            else:\n",
    "                # Fallback to just clinical patients\n",
    "                print(f\"Using {len(clinical_patients)} patients with clinical data\")\n",
    "                common_patients = clinical_patients\n",
    "    \n",
    "    # Get cancer type distribution for chosen patients\n",
    "    patient_cancer_types = clinical_df[clinical_df['patient_id'].isin(common_patients)]['cancer_type'].value_counts()\n",
    "    print(\"\\nCancer type distribution for selected patients:\")\n",
    "    print(patient_cancer_types)\n",
    "    \n",
    "    # # Limit to a reasonable number of patients for visualization (max 500)\n",
    "    # if len(common_patients) > 500:\n",
    "    #     print(f\"Limiting to 500 patients for visualization (from {len(common_patients)} total)\")\n",
    "    #     # Try to balance cancer types\n",
    "    #     patients_by_cancer = {}\n",
    "    #     for patient_id in common_patients:\n",
    "    #         # Find cancer type\n",
    "    #         cancer_type = None\n",
    "    #         if patient_id in set(clinical_df['patient_id']):\n",
    "    #             cancer_type = clinical_df[clinical_df['patient_id'] == patient_id]['cancer_type'].iloc[0]\n",
    "            \n",
    "    #         if cancer_type:\n",
    "    #             if cancer_type not in patients_by_cancer:\n",
    "    #                 patients_by_cancer[cancer_type] = []\n",
    "    #             patients_by_cancer[cancer_type].append(patient_id)\n",
    "        \n",
    "    #     # Select equal numbers from each cancer type if possible\n",
    "    #     balanced_patients = []\n",
    "    #     patients_per_type = 500 // len(patients_by_cancer)\n",
    "        \n",
    "    #     for cancer_type, patients in patients_by_cancer.items():\n",
    "    #         balanced_patients.extend(patients[:patients_per_type])\n",
    "        \n",
    "    #     # If we need more, add from the largest categories\n",
    "    #     while len(balanced_patients) < 500 and any(len(p) > patients_per_type for p in patients_by_cancer.values()):\n",
    "    #         for cancer_type, patients in sorted(patients_by_cancer.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    #             if len(balanced_patients) >= 500:\n",
    "    #                 break\n",
    "    #             if len(patients) > patients_per_type:\n",
    "    #                 balanced_patients.append(patients[patients_per_type])\n",
    "    #                 patients_per_type += 1\n",
    "        \n",
    "    #     common_patients = set(balanced_patients)\n",
    "    \n",
    "    # Filter dataframes to keep only common patients\n",
    "    clinical_filtered = clinical_df[clinical_df['patient_id'].isin(common_patients)]\n",
    "    pathology_filtered = pathology_df[pathology_df['patient_id'].isin(common_patients)]\n",
    "    radiology_filtered = radiology_df[radiology_df['patient_id'].isin(common_patients)]\n",
    "    molecular_filtered = molecular_df[molecular_df['patient_id'].isin(common_patients)]\n",
    "    \n",
    "    # Create aligned dataframe with consistent patient ordering\n",
    "    common_patients_list = sorted(list(common_patients))\n",
    "    aligned_data = pd.DataFrame({'patient_id': common_patients_list})\n",
    "    \n",
    "    # Merge cancer type\n",
    "    aligned_data = aligned_data.merge(\n",
    "        clinical_filtered[['patient_id', 'cancer_type']],\n",
    "        on='patient_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill missing cancer types\n",
    "    for df in [pathology_filtered, radiology_filtered, molecular_filtered]:\n",
    "        if len(df) > 0:\n",
    "            missing_mask = aligned_data['cancer_type'].isna()\n",
    "            if missing_mask.any():\n",
    "                for idx, row in aligned_data[missing_mask].iterrows():\n",
    "                    patient_match = df[df['patient_id'] == row['patient_id']]\n",
    "                    if len(patient_match) > 0 and 'cancer_type' in patient_match.columns:\n",
    "                        aligned_data.loc[idx, 'cancer_type'] = patient_match['cancer_type'].iloc[0]\n",
    "    \n",
    "    # Fill any still missing cancer types with default\n",
    "    missing_mask = aligned_data['cancer_type'].isna()\n",
    "    if missing_mask.any():\n",
    "        print(f\"Still missing cancer type for {missing_mask.sum()} patients. Using default.\")\n",
    "        aligned_data.loc[missing_mask, 'cancer_type'] = TARGET_CANCER_TYPES[0]\n",
    "    \n",
    "    # Get embedding shapes for defaults\n",
    "    clinical_embedding_shape = None\n",
    "    pathology_embedding_shape = None\n",
    "    radiology_embedding_shape = None\n",
    "    molecular_embedding_shape = None\n",
    "    \n",
    "    if len(clinical_filtered) > 0:\n",
    "        clinical_embedding_shape = clinical_filtered['embeddings'].iloc[0].shape\n",
    "    if len(pathology_filtered) > 0:\n",
    "        pathology_embedding_shape = pathology_filtered['embeddings'].iloc[0].shape\n",
    "    if len(radiology_filtered) > 0:\n",
    "        radiology_embedding_shape = radiology_filtered['embeddings'].iloc[0].shape\n",
    "    if len(molecular_filtered) > 0:\n",
    "        molecular_embedding_shape = molecular_filtered['embeddings'].iloc[0].shape\n",
    "    \n",
    "    # Use default shapes if not found\n",
    "    if clinical_embedding_shape is None:\n",
    "        clinical_embedding_shape = (1024,)\n",
    "    if pathology_embedding_shape is None:\n",
    "        pathology_embedding_shape = (1024,)\n",
    "    if radiology_embedding_shape is None:\n",
    "        radiology_embedding_shape = (1000,)\n",
    "    if molecular_embedding_shape is None:\n",
    "        molecular_embedding_shape = (48,)\n",
    "    \n",
    "    # Initialize embedding columns as object type to hold arrays\n",
    "    aligned_data['clinical_embedding'] = None\n",
    "    aligned_data['pathology_embedding'] = None\n",
    "    aligned_data['radiology_embedding'] = None\n",
    "    aligned_data['molecular_embedding'] = None\n",
    "    \n",
    "    # Add embeddings for each modality\n",
    "    for patient_id in tqdm(common_patients_list, desc=\"Aligning embeddings\"):\n",
    "        # Get the index for this patient\n",
    "        patient_idx = aligned_data.index[aligned_data['patient_id'] == patient_id].tolist()[0]\n",
    "        \n",
    "        # Add clinical embeddings\n",
    "        clinical_match = clinical_filtered[clinical_filtered['patient_id'] == patient_id]\n",
    "        if len(clinical_match) > 0:\n",
    "            aligned_data.at[patient_idx, 'clinical_embedding'] = clinical_match['embeddings'].values[0]\n",
    "        else:\n",
    "            aligned_data.at[patient_idx, 'clinical_embedding'] = np.zeros(clinical_embedding_shape)\n",
    "        \n",
    "        # Add pathology embeddings\n",
    "        pathology_match = pathology_filtered[pathology_filtered['patient_id'] == patient_id]\n",
    "        if len(pathology_match) > 0:\n",
    "            aligned_data.at[patient_idx, 'pathology_embedding'] = pathology_match['embeddings'].values[0]\n",
    "        else:\n",
    "            aligned_data.at[patient_idx, 'pathology_embedding'] = np.zeros(pathology_embedding_shape)\n",
    "        \n",
    "        # Add radiology embeddings\n",
    "        radiology_match = radiology_filtered[radiology_filtered['patient_id'] == patient_id]\n",
    "        if len(radiology_match) > 0:\n",
    "            aligned_data.at[patient_idx, 'radiology_embedding'] = radiology_match['embeddings'].values[0]\n",
    "        else:\n",
    "            aligned_data.at[patient_idx, 'radiology_embedding'] = np.zeros(radiology_embedding_shape)\n",
    "        \n",
    "        # Add molecular embeddings\n",
    "        molecular_match = molecular_filtered[molecular_filtered['patient_id'] == patient_id]\n",
    "        if len(molecular_match) > 0:\n",
    "            aligned_data.at[patient_idx, 'molecular_embedding'] = molecular_match['embeddings'].values[0]\n",
    "        else:\n",
    "            aligned_data.at[patient_idx, 'molecular_embedding'] = np.zeros(molecular_embedding_shape)\n",
    "    \n",
    "    return aligned_data\n",
    "\n",
    "def create_multimodal_embeddings(aligned_data):\n",
    "    \"\"\"\n",
    "    Create integrated multimodal embeddings by concatenating modality embeddings\n",
    "    \"\"\"\n",
    "    print(\"Creating multimodal embeddings...\")\n",
    "    \n",
    "    # Handle multi-dimensional embeddings by extracting and flattening if needed\n",
    "    clinical_embeddings = []\n",
    "    pathology_embeddings = []\n",
    "    radiology_embeddings = []\n",
    "    molecular_embeddings = []\n",
    "    \n",
    "    for _, row in aligned_data.iterrows():\n",
    "        # Process clinical embedding\n",
    "        emb = row['clinical_embedding']\n",
    "        if emb is None:\n",
    "            clinical_embeddings.append(np.zeros(1024))\n",
    "        elif len(np.array(emb).shape) > 1:\n",
    "            # If multi-dimensional, flatten or take mean\n",
    "            emb_array = np.array(emb)\n",
    "            if len(emb_array.shape) == 2:\n",
    "                # Take mean along first dimension for 2D arrays\n",
    "                clinical_embeddings.append(np.mean(emb_array, axis=0))\n",
    "            else:\n",
    "                # For higher dimensions, flatten to 1D\n",
    "                clinical_embeddings.append(np.array(emb).flatten())\n",
    "        else:\n",
    "            clinical_embeddings.append(np.array(emb))\n",
    "        \n",
    "        # Process pathology embedding\n",
    "        emb = row['pathology_embedding']\n",
    "        if emb is None:\n",
    "            pathology_embeddings.append(np.zeros(1024))\n",
    "        elif len(np.array(emb).shape) > 1:\n",
    "            emb_array = np.array(emb)\n",
    "            if len(emb_array.shape) == 2:\n",
    "                pathology_embeddings.append(np.mean(emb_array, axis=0))\n",
    "            else:\n",
    "                pathology_embeddings.append(np.array(emb).flatten())\n",
    "        else:\n",
    "            pathology_embeddings.append(np.array(emb))\n",
    "        \n",
    "        # Process radiology embedding\n",
    "        emb = row['radiology_embedding']\n",
    "        if emb is None:\n",
    "            radiology_embeddings.append(np.zeros(1000))\n",
    "        elif len(np.array(emb).shape) > 1:\n",
    "            emb_array = np.array(emb)\n",
    "            if len(emb_array.shape) == 2:\n",
    "                radiology_embeddings.append(np.mean(emb_array, axis=0))\n",
    "            else:\n",
    "                radiology_embeddings.append(np.array(emb).flatten())\n",
    "        else:\n",
    "            radiology_embeddings.append(np.array(emb))\n",
    "        \n",
    "        # Process molecular embedding\n",
    "        emb = row['molecular_embedding']\n",
    "        if emb is None:\n",
    "            molecular_embeddings.append(np.zeros(48))\n",
    "        elif len(np.array(emb).shape) > 1:\n",
    "            emb_array = np.array(emb)\n",
    "            if len(emb_array.shape) == 2:\n",
    "                molecular_embeddings.append(np.mean(emb_array, axis=0))\n",
    "            else:\n",
    "                molecular_embeddings.append(np.array(emb).flatten())\n",
    "        else:\n",
    "            molecular_embeddings.append(np.array(emb))\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    clinical_embeddings = np.array(clinical_embeddings)\n",
    "    pathology_embeddings = np.array(pathology_embeddings)\n",
    "    radiology_embeddings = np.array(radiology_embeddings)\n",
    "    molecular_embeddings = np.array(molecular_embeddings)\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"Clinical embeddings shape: {clinical_embeddings.shape}\")\n",
    "    print(f\"Pathology embeddings shape: {pathology_embeddings.shape}\")\n",
    "    print(f\"Radiology embeddings shape: {radiology_embeddings.shape}\")\n",
    "    print(f\"Molecular embeddings shape: {molecular_embeddings.shape}\")\n",
    "    \n",
    "    # Normalize each modality separately\n",
    "    clinical_scaled = StandardScaler().fit_transform(clinical_embeddings)\n",
    "    pathology_scaled = StandardScaler().fit_transform(pathology_embeddings)\n",
    "    radiology_scaled = StandardScaler().fit_transform(radiology_embeddings)\n",
    "    molecular_scaled = StandardScaler().fit_transform(molecular_embeddings)\n",
    "    \n",
    "    # Create multimodal embeddings by concatenation\n",
    "    multimodal_embeddings = np.hstack([\n",
    "        clinical_scaled, \n",
    "        pathology_scaled, \n",
    "        radiology_scaled, \n",
    "        molecular_scaled\n",
    "    ])\n",
    "    \n",
    "    print(f\"Multimodal embeddings shape: {multimodal_embeddings.shape}\")\n",
    "    \n",
    "    return multimodal_embeddings\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance\n",
    "import os\n",
    "\n",
    "# Add this function to the existing code\n",
    "def evaluate_embedding_quality(aligned_data, umap_embeddings_dict, output_dir):\n",
    "    \"\"\"\n",
    "    Quantitatively evaluate the quality of different embeddings (unimodal vs multimodal)\n",
    "    based on clustering metrics.\n",
    "    \n",
    "    Args:\n",
    "        aligned_data: DataFrame with patient data and cancer type labels\n",
    "        umap_embeddings_dict: Dictionary containing UMAP embeddings for each modality\n",
    "        output_dir: Directory to save the evaluation results\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluating embedding quality for each modality...\")\n",
    "    \n",
    "    # Get true labels (cancer types)\n",
    "    true_labels = aligned_data['cancer_type'].values\n",
    "    unique_labels = aligned_data['cancer_type'].unique()\n",
    "    num_clusters = len(unique_labels)\n",
    "    \n",
    "    # Create numeric labels for clustering metrics\n",
    "    label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "    numeric_labels = np.array([label_map[label] for label in true_labels])\n",
    "    \n",
    "    # Initialize dictionary to store metrics\n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    # Initialize clustering algorithms\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "    \n",
    "    # Evaluate each modality\n",
    "    for modality, embeddings in umap_embeddings_dict.items():\n",
    "        print(f\"Evaluating {modality} embeddings...\")\n",
    "        \n",
    "        # Skip if embeddings are empty\n",
    "        if len(embeddings) == 0:\n",
    "            print(f\"  Skipping {modality} - no embeddings available\")\n",
    "            continue\n",
    "            \n",
    "        # 1. Silhouette Score - measures how well samples are clustered with samples of the same class\n",
    "        try:\n",
    "            silhouette_avg = metrics.silhouette_score(embeddings, numeric_labels)\n",
    "        except:\n",
    "            silhouette_avg = float('nan')\n",
    "            print(f\"  Could not compute silhouette score for {modality}\")\n",
    "        \n",
    "        # 2. Davies-Bouldin Index - lower values indicate better separation\n",
    "        try:\n",
    "            davies_bouldin = metrics.davies_bouldin_score(embeddings, numeric_labels)\n",
    "        except:\n",
    "            davies_bouldin = float('nan')\n",
    "            print(f\"  Could not compute Davies-Bouldin score for {modality}\")\n",
    "        \n",
    "        # 3. Calinski-Harabasz Index - higher values indicate better defined clusters\n",
    "        try:\n",
    "            calinski_harabasz = metrics.calinski_harabasz_score(embeddings, numeric_labels)\n",
    "        except:\n",
    "            calinski_harabasz = float('nan')\n",
    "            print(f\"  Could not compute Calinski-Harabasz score for {modality}\")\n",
    "        \n",
    "        # 4. Apply K-means clustering and compute metrics\n",
    "        try:\n",
    "            kmeans_labels = kmeans.fit_predict(embeddings)\n",
    "            kmeans_ami = metrics.adjusted_mutual_info_score(numeric_labels, kmeans_labels)\n",
    "            kmeans_ari = metrics.adjusted_rand_score(numeric_labels, kmeans_labels)\n",
    "            kmeans_v_measure = metrics.v_measure_score(numeric_labels, kmeans_labels)\n",
    "        except:\n",
    "            kmeans_ami = kmeans_ari = kmeans_v_measure = float('nan')\n",
    "            print(f\"  Could not compute K-means metrics for {modality}\")\n",
    "        \n",
    "        # 5. Apply DBSCAN clustering and compute metrics\n",
    "        try:\n",
    "            dbscan_labels = dbscan.fit_predict(embeddings)\n",
    "            # Only compute metrics if DBSCAN found multiple clusters\n",
    "            if len(np.unique(dbscan_labels)) > 1 and -1 not in dbscan_labels:\n",
    "                dbscan_ami = metrics.adjusted_mutual_info_score(numeric_labels, dbscan_labels)\n",
    "                dbscan_ari = metrics.adjusted_rand_score(numeric_labels, dbscan_labels)\n",
    "                dbscan_v_measure = metrics.v_measure_score(numeric_labels, dbscan_labels)\n",
    "            else:\n",
    "                dbscan_ami = dbscan_ari = dbscan_v_measure = float('nan')\n",
    "                print(f\"  DBSCAN did not find valid clusters for {modality}\")\n",
    "        except:\n",
    "            dbscan_ami = dbscan_ari = dbscan_v_measure = float('nan')\n",
    "            print(f\"  Could not compute DBSCAN metrics for {modality}\")\n",
    "        \n",
    "        # 6. Compute average distance between cancer types\n",
    "        try:\n",
    "            cancer_centroids = {}\n",
    "            for cancer in unique_labels:\n",
    "                mask = aligned_data['cancer_type'] == cancer\n",
    "                if np.sum(mask) > 0:\n",
    "                    cancer_centroids[cancer] = np.mean(embeddings[mask], axis=0)\n",
    "            \n",
    "            # Compute pairwise distances between centroids\n",
    "            if len(cancer_centroids) > 1:\n",
    "                centroid_vectors = np.array(list(cancer_centroids.values()))\n",
    "                pairwise_distances = distance.pdist(centroid_vectors, 'euclidean')\n",
    "                avg_intercluster_distance = np.mean(pairwise_distances)\n",
    "            else:\n",
    "                avg_intercluster_distance = float('nan')\n",
    "        except:\n",
    "            avg_intercluster_distance = float('nan')\n",
    "            print(f\"  Could not compute intercluster distances for {modality}\")\n",
    "        \n",
    "        # Add metrics to dataframe\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame({\n",
    "            'Modality': [modality],\n",
    "            'Silhouette Score': [silhouette_avg],\n",
    "            'Davies-Bouldin Index': [davies_bouldin],\n",
    "            'Calinski-Harabasz Index': [calinski_harabasz],\n",
    "            'K-means AMI': [kmeans_ami],\n",
    "            'K-means ARI': [kmeans_ari],\n",
    "            'K-means V-measure': [kmeans_v_measure],\n",
    "            'DBSCAN AMI': [dbscan_ami],\n",
    "            'DBSCAN ARI': [dbscan_ari],\n",
    "            'DBSCAN V-measure': [dbscan_v_measure],\n",
    "            'Avg Intercluster Distance': [avg_intercluster_distance]\n",
    "        })], ignore_index=True)\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    metrics_df.to_csv(os.path.join(output_dir, 'embedding_quality_metrics.csv'), index=False)\n",
    "    \n",
    "    # Create a formatted table for display\n",
    "    with open(os.path.join(output_dir, 'embedding_quality_report.txt'), 'w') as f:\n",
    "        f.write(\"Embedding Quality Evaluation\\n\")\n",
    "        f.write(\"===========================\\n\\n\")\n",
    "        f.write(f\"Number of cancer types: {num_clusters}\\n\")\n",
    "        f.write(f\"Total samples: {len(aligned_data)}\\n\\n\")\n",
    "        f.write(\"Metrics (higher is better except for Davies-Bouldin Index):\\n\\n\")\n",
    "        f.write(metrics_df.to_string(index=False))\n",
    "    \n",
    "    print(f\"Evaluation results saved to {output_dir}\")\n",
    "    \n",
    "    # Create visualization of metrics\n",
    "    plot_embedding_metrics(metrics_df, output_dir)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def plot_embedding_metrics(metrics_df, output_dir):\n",
    "    \"\"\"\n",
    "    Create visualizations of the embedding quality metrics for comparison\n",
    "    \"\"\"\n",
    "    # Create a multi-panel figure for metrics comparison\n",
    "    plt.figure(figsize=(18, 15))\n",
    "    \n",
    "    metrics_to_plot = [\n",
    "        ('Silhouette Score', 'Higher is better'),\n",
    "        ('Davies-Bouldin Index', 'Lower is better'),\n",
    "        ('Calinski-Harabasz Index', 'Higher is better'),\n",
    "        ('K-means AMI', 'Higher is better'),\n",
    "        ('K-means ARI', 'Higher is better'),\n",
    "        ('K-means V-measure', 'Higher is better'),\n",
    "    ]\n",
    "    \n",
    "    for i, (metric, subtitle) in enumerate(metrics_to_plot):\n",
    "        plt.subplot(3, 2, i+1)\n",
    "        \n",
    "        # Sort by metric value for better visualization\n",
    "        df_sorted = metrics_df.sort_values(by=metric)\n",
    "        \n",
    "        # Create barplot\n",
    "        ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for j, p in enumerate(ax.patches):\n",
    "            ax.annotate(f\"{p.get_height():.3f}\", \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=10, color='black',\n",
    "                        xytext=(0, 5),\n",
    "                        textcoords='offset points')\n",
    "        \n",
    "        plt.title(f\"{metric}\\n{subtitle}\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.suptitle(\"Embedding Quality Metrics Comparison\", fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'embedding_metrics_comparison.png'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a radar chart for multi-metric comparison\n",
    "    create_radar_chart(metrics_df, output_dir)\n",
    "\n",
    "def create_radar_chart(metrics_df, output_dir):\n",
    "    \"\"\"\n",
    "    Create a radar chart to compare multiple metrics across different modalities\n",
    "    \"\"\"\n",
    "    # Select metrics for radar chart\n",
    "    metrics_for_radar = [\n",
    "        'Silhouette Score', \n",
    "        'K-means AMI', \n",
    "        'K-means ARI', \n",
    "        'K-means V-measure',\n",
    "        'Avg Intercluster Distance'\n",
    "    ]\n",
    "    \n",
    "    # Filter and clean data\n",
    "    radar_df = metrics_df[['Modality'] + metrics_for_radar].copy()\n",
    "    \n",
    "    # Replace NaN with 0 for visualization\n",
    "    radar_df = radar_df.fillna(0)\n",
    "    \n",
    "    # Normalize metrics to 0-1 scale for comparison\n",
    "    for metric in metrics_for_radar:\n",
    "        if metric != 'Davies-Bouldin Index':  # For metrics where higher is better\n",
    "            if radar_df[metric].max() > 0:\n",
    "                radar_df[metric] = radar_df[metric] / radar_df[metric].max()\n",
    "        else:  # For Davies-Bouldin where lower is better\n",
    "            if radar_df[metric].max() > 0:\n",
    "                radar_df[metric] = 1 - (radar_df[metric] / radar_df[metric].max())\n",
    "    \n",
    "    # Set up radar chart\n",
    "    n_metrics = len(metrics_for_radar)\n",
    "    angles = np.linspace(0, 2*np.pi, n_metrics, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    # Add lines for each modality\n",
    "    for i, modality in enumerate(radar_df['Modality']):\n",
    "        values = radar_df.loc[radar_df['Modality'] == modality, metrics_for_radar].values.flatten().tolist()\n",
    "        values += values[:1]  # Close the loop\n",
    "        \n",
    "        # Plot values\n",
    "        ax.plot(angles, values, linewidth=2, label=modality)\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), metrics_for_radar)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    \n",
    "    plt.title('Multimodal vs. Unimodal Embedding Quality Comparison', size=15, y=1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'embedding_radar_comparison.png'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def compute_cluster_separability(aligned_data, umap_embeddings_dict, output_dir):\n",
    "    \"\"\"\n",
    "    Compute separability of cancer type clusters for each modality\n",
    "    \"\"\"\n",
    "    print(\"\\nComputing cluster separability metrics...\")\n",
    "    \n",
    "    # Get unique cancer types\n",
    "    cancer_types = aligned_data['cancer_type'].unique()\n",
    "    \n",
    "    # Initialize results dataframe\n",
    "    separability_df = pd.DataFrame()\n",
    "    \n",
    "    # Compute metrics for each modality\n",
    "    for modality, embeddings in umap_embeddings_dict.items():\n",
    "        print(f\"Analyzing {modality} embeddings...\")\n",
    "        \n",
    "        # Skip if embeddings are empty\n",
    "        if len(embeddings) == 0:\n",
    "            print(f\"  Skipping {modality} - no embeddings available\")\n",
    "            continue\n",
    "        \n",
    "        # Compute cancer type centroids\n",
    "        centroids = {}\n",
    "        for cancer in cancer_types:\n",
    "            mask = aligned_data['cancer_type'] == cancer\n",
    "            if np.sum(mask) > 0:\n",
    "                centroids[cancer] = np.mean(embeddings[mask], axis=0)\n",
    "        \n",
    "        # Compute within-cluster scatter\n",
    "        within_scatter = 0\n",
    "        for cancer in cancer_types:\n",
    "            mask = aligned_data['cancer_type'] == cancer\n",
    "            if np.sum(mask) > 0:\n",
    "                dist_to_centroid = np.mean(\n",
    "                    np.sqrt(np.sum((embeddings[mask] - centroids[cancer])**2, axis=1))\n",
    "                )\n",
    "                within_scatter += dist_to_centroid\n",
    "        \n",
    "        # Average within-cluster scatter\n",
    "        avg_within_scatter = within_scatter / len(cancer_types)\n",
    "        \n",
    "        # Compute between-cluster distances\n",
    "        between_distances = []\n",
    "        for i, cancer1 in enumerate(cancer_types):\n",
    "            if cancer1 not in centroids:\n",
    "                continue\n",
    "            for j, cancer2 in enumerate(cancer_types[i+1:]):\n",
    "                if cancer2 not in centroids:\n",
    "                    continue\n",
    "                dist = np.sqrt(np.sum((centroids[cancer1] - centroids[cancer2])**2))\n",
    "                between_distances.append(dist)\n",
    "        \n",
    "        # Average between-cluster distance\n",
    "        avg_between_distance = np.mean(between_distances) if between_distances else 0\n",
    "        \n",
    "        # Compute separation ratio (higher is better)\n",
    "        separation_ratio = avg_between_distance / avg_within_scatter if avg_within_scatter > 0 else 0\n",
    "        \n",
    "        # Compute silhouette coefficients for each cancer type\n",
    "        cancer_silhouettes = {}\n",
    "        for cancer in cancer_types:\n",
    "            mask = aligned_data['cancer_type'] == cancer\n",
    "            if np.sum(mask) >= 3:  # Need at least 3 samples for meaningful silhouette\n",
    "                try:\n",
    "                    cancer_sil = metrics.silhouette_score(embeddings[mask], np.zeros(np.sum(mask)))\n",
    "                    cancer_silhouettes[cancer] = cancer_sil\n",
    "                except:\n",
    "                    cancer_silhouettes[cancer] = float('nan')\n",
    "        \n",
    "        # Add to results dataframe\n",
    "        separability_df = pd.concat([separability_df, pd.DataFrame({\n",
    "            'Modality': [modality],\n",
    "            'Avg Within-Cluster Scatter': [avg_within_scatter],\n",
    "            'Avg Between-Cluster Distance': [avg_between_distance],\n",
    "            'Separation Ratio': [separation_ratio],\n",
    "        })], ignore_index=True)\n",
    "    \n",
    "    # Save results\n",
    "    separability_df.to_csv(os.path.join(output_dir, 'cluster_separability_metrics.csv'), index=False)\n",
    "    \n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot separation ratio\n",
    "    plt.subplot(1, 2, 1)\n",
    "    df_sorted = separability_df.sort_values(by='Separation Ratio', ascending=False)\n",
    "    sns.barplot(x='Modality', y='Separation Ratio', data=df_sorted, palette='viridis')\n",
    "    plt.title('Cluster Separation Ratio\\n(Higher is Better)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Plot scatter vs distance\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i, row in separability_df.iterrows():\n",
    "        plt.scatter(\n",
    "            row['Avg Within-Cluster Scatter'], \n",
    "            row['Avg Between-Cluster Distance'],\n",
    "            s=100, \n",
    "            label=row['Modality']\n",
    "        )\n",
    "        plt.text(\n",
    "            row['Avg Within-Cluster Scatter'] + 0.01, \n",
    "            row['Avg Between-Cluster Distance'] + 0.01,\n",
    "            row['Modality']\n",
    "        )\n",
    "    \n",
    "    # Add diagonal line where ratio = 1\n",
    "    max_val = max(separability_df['Avg Within-Cluster Scatter'].max(), \n",
    "                  separability_df['Avg Between-Cluster Distance'].max()) * 1.1\n",
    "    plt.plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "    \n",
    "    plt.xlabel('Average Within-Cluster Scatter (Lower is Better)')\n",
    "    plt.ylabel('Average Between-Cluster Distance (Higher is Better)')\n",
    "    plt.title('Cluster Separation Analysis')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'cluster_separability.png'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return separability_df\n",
    "\n",
    "# This function will perform more advanced clustering analysis\n",
    "def perform_clustering_analysis(aligned_data, umap_embeddings_dict, output_dir):\n",
    "    \"\"\"\n",
    "    Perform clustering analysis to compare how well different embedding spaces \n",
    "    correlate with cancer type clusters\n",
    "    \"\"\"\n",
    "    print(\"\\nPerforming clustering analysis...\")\n",
    "    \n",
    "    # Get cancer types and create color mapping\n",
    "    cancer_types = aligned_data['cancer_type'].unique()\n",
    "    colors = sns.color_palette(\"tab10\", len(cancer_types))\n",
    "    color_map = {cancer: color for cancer, color in zip(cancer_types, colors)}\n",
    "    \n",
    "    # Initialize result metrics\n",
    "    cluster_metrics = []\n",
    "    \n",
    "    # Analyze each modality\n",
    "    for modality, embeddings in umap_embeddings_dict.items():\n",
    "        print(f\"Analyzing {modality} embeddings...\")\n",
    "        \n",
    "        # Skip if embeddings are empty\n",
    "        if len(embeddings) == 0:\n",
    "            print(f\"  Skipping {modality} - no embeddings available\")\n",
    "            continue\n",
    "        \n",
    "        # Try different cluster counts\n",
    "        k_values = [len(cancer_types), len(cancer_types)+1, len(cancer_types)+2]\n",
    "        \n",
    "        for k in k_values:\n",
    "            # Apply K-means clustering\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            cluster_labels = kmeans.fit_predict(embeddings)\n",
    "            \n",
    "            # Calculate metrics comparing clusters to cancer types\n",
    "            true_labels = aligned_data['cancer_type'].values\n",
    "            \n",
    "            # Convert true labels to numeric\n",
    "            label_map = {label: i for i, label in enumerate(cancer_types)}\n",
    "            numeric_true_labels = np.array([label_map[label] for label in true_labels])\n",
    "            \n",
    "            # Calculate agreement metrics\n",
    "            ami = metrics.adjusted_mutual_info_score(true_labels, cluster_labels)\n",
    "            ari = metrics.adjusted_rand_score(true_labels, cluster_labels)\n",
    "            v_measure = metrics.v_measure_score(true_labels, cluster_labels)\n",
    "            \n",
    "            # Store metrics\n",
    "            cluster_metrics.append({\n",
    "                'Modality': modality,\n",
    "                'K': k,\n",
    "                'AMI': ami,\n",
    "                'ARI': ari,\n",
    "                'V-measure': v_measure\n",
    "            })\n",
    "            \n",
    "            # Create visualization of clusters vs cancer types\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            \n",
    "            # First subplot: clusters\n",
    "            plt.subplot(2, 1, 1)\n",
    "            for i in range(k):\n",
    "                mask = cluster_labels == i\n",
    "                if np.sum(mask) > 0:\n",
    "                    plt.scatter(\n",
    "                        embeddings[mask, 0],\n",
    "                        embeddings[mask, 1],\n",
    "                        label=f'Cluster {i}',\n",
    "                        alpha=0.7,\n",
    "                        s=50,\n",
    "                        edgecolor='none'\n",
    "                    )\n",
    "            \n",
    "            plt.title(f'{modality} - K-means Clusters (k={k})')\n",
    "            plt.xlabel('UMAP 1')\n",
    "            plt.ylabel('UMAP 2')\n",
    "            plt.legend(title=\"Clusters\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            \n",
    "            # Second subplot: actual cancer types\n",
    "            plt.subplot(2, 1, 2)\n",
    "            for cancer_type in cancer_types:\n",
    "                mask = aligned_data['cancer_type'] == cancer_type\n",
    "                if np.sum(mask) > 0:\n",
    "                    plt.scatter(\n",
    "                        embeddings[mask, 0],\n",
    "                        embeddings[mask, 1],\n",
    "                        label=cancer_type,\n",
    "                        color=color_map[cancer_type],\n",
    "                        alpha=0.7,\n",
    "                        s=50,\n",
    "                        edgecolor='none'\n",
    "                    )\n",
    "            \n",
    "            plt.title(f'{modality} - Actual Cancer Types')\n",
    "            plt.xlabel('UMAP 1')\n",
    "            plt.ylabel('UMAP 2')\n",
    "            plt.legend(title=\"Cancer Types\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                os.path.join(output_dir, f'{modality}_clusters_k{k}.png'),\n",
    "                bbox_inches='tight', \n",
    "                dpi=300\n",
    "            )\n",
    "            plt.close()\n",
    "    \n",
    "    # Convert metrics to DataFrame\n",
    "    cluster_metrics_df = pd.DataFrame(cluster_metrics)\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    cluster_metrics_df.to_csv(os.path.join(output_dir, 'clustering_analysis_metrics.csv'), index=False)\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot AMI for each modality and k\n",
    "    plt.subplot(1, 3, 1)\n",
    "    pivot_ami = cluster_metrics_df.pivot(index='Modality', columns='K', values='AMI')\n",
    "    sns.heatmap(pivot_ami, annot=True, cmap='viridis', fmt='.3f')\n",
    "    plt.title('Adjusted Mutual Information (Higher is Better)')\n",
    "    \n",
    "    # Plot ARI for each modality and k\n",
    "    plt.subplot(1, 3, 2)\n",
    "    pivot_ari = cluster_metrics_df.pivot(index='Modality', columns='K', values='ARI')\n",
    "    sns.heatmap(pivot_ari, annot=True, cmap='viridis', fmt='.3f')\n",
    "    plt.title('Adjusted Rand Index (Higher is Better)')\n",
    "    \n",
    "    # Plot V-measure for each modality and k\n",
    "    plt.subplot(1, 3, 3)\n",
    "    pivot_v = cluster_metrics_df.pivot(index='Modality', columns='K', values='V-measure')\n",
    "    sns.heatmap(pivot_v, annot=True, cmap='viridis', fmt='.3f')\n",
    "    plt.title('V-measure (Higher is Better)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'clustering_metrics_comparison.png'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return cluster_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clinical data...\n",
      "Loaded 11428 total clinical samples\n",
      "After filtering for ['TCGA-KIRC', 'TCGA-OV', 'TCGA-BRCA'], found 2243 clinical samples\n",
      "After removing null embeddings, 2243 clinical samples remain\n",
      "Using embedding_shape for clinical embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9389a83138ca45e09c3ee442b87502cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing clinical embeddings:   0%|          | 0/2243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2243 unique patients in clinical data\n",
      "Loading pathology report data...\n",
      "Loaded 11208 total pathology samples\n",
      "After filtering by patient IDs, found 2250 pathology samples out of 11208\n",
      "After removing null embeddings, 2250 pathology samples remain\n",
      "Using embedding_shape for pathology embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5232c1e53e9f44beb2b21a06d0735513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing pathology embeddings:   0%|          | 0/2250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading radiology data...\n",
      "Loaded 11870 total radiology samples\n",
      "After filtering by patient IDs, found 5532 radiology samples out of 11870\n",
      "After removing null embeddings, 5257 radiology samples remain\n",
      "Using embedding_shape for radiology embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380238d5fee9426999866a010f98340c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing radiology embeddings:   0%|          | 0/5257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading molecular data...\n",
      "Loaded 13804 total molecular samples\n",
      "Molecular data columns: ['PatientID', 'SampleID', 'Embeddings']\n",
      "After filtering by patient IDs, found 2970 molecular samples out of 13804\n",
      "After removing null embeddings, 2970 molecular samples remain\n",
      "No embedding_shape for molecular embeddings, using raw buffers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c23b5d74d54479da37fe56231ffbbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing molecular embeddings:   0%|          | 0/2970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final summary:\n",
      "Clinical data: 2243 samples\n",
      "Pathology data: 2250 samples\n",
      "Radiology data: 5257 samples\n",
      "Molecular data: 2970 samples\n"
     ]
    }
   ],
   "source": [
    "# Load data from all modalities\n",
    "clinical_df, pathology_df, radiology_df, molecular_df = load_multimodal_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning patient data across modalities...\n",
      "Clinical patients: 2243\n",
      "Pathology patients: 2225\n",
      "Radiology patients: 548\n",
      "Molecular patients: 2192\n",
      "Patients in clinical and pathology: 2225\n",
      "Patients in clinical and radiology: 548\n",
      "Patients in clinical and molecular: 2192\n",
      "Found 547 patients with data in all four modalities\n",
      "Using 547 patients with data in all modalities\n",
      "\n",
      "Cancer type distribution for selected patients:\n",
      "cancer_type\n",
      "TCGA-KIRC    267\n",
      "TCGA-OV      141\n",
      "TCGA-BRCA    139\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfeb840c898452d933faf7e4362e566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning embeddings:   0%|          | 0/547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Align patient data across modalities\n",
    "aligned_data = align_patient_data(clinical_df, pathology_df, radiology_df, molecular_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating multimodal embeddings...\n",
      "Clinical embeddings shape: (547, 1024)\n",
      "Pathology embeddings shape: (547, 1024)\n",
      "Radiology embeddings shape: (547, 1000)\n",
      "Molecular embeddings shape: (547, 48)\n",
      "Multimodal embeddings shape: (547, 3096)\n"
     ]
    }
   ],
   "source": [
    "# Create multimodal embeddings\n",
    "multimodal_embeddings = create_multimodal_embeddings(aligned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing multimodal integration and performing quantitative analysis...\n",
      "Clinical embeddings processed shape: (547, 1024)\n",
      "Pathology embeddings processed shape: (547, 1024)\n",
      "Radiology embeddings processed shape: (547, 1000)\n",
      "Molecular embeddings processed shape: (547, 48)\n",
      "WARNING: Found 22000 NaN values in radiology embeddings. Replacing with zeros.\n",
      "WARNING: Found 22000 NaN values in multimodal embeddings. Replacing with zeros.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aakash/miniconda3/envs/HoneyBee/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/aakash/miniconda3/envs/HoneyBee/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/home/aakash/miniconda3/envs/HoneyBee/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/aakash/miniconda3/envs/HoneyBee/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/aakash/miniconda3/envs/HoneyBee/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/aakash/miniconda3/envs/HoneyBee/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer types in visualization: ['TCGA-OV' 'TCGA-BRCA' 'TCGA-KIRC']\n",
      "Visualizations saved to multimodal_analysis_results\n",
      "\n",
      "Evaluating embedding quality for each modality...\n",
      "Evaluating Clinical embeddings...\n",
      "Evaluating Pathology embeddings...\n",
      "  DBSCAN did not find valid clusters for Pathology\n",
      "Evaluating Radiology embeddings...\n",
      "  DBSCAN did not find valid clusters for Radiology\n",
      "Evaluating Molecular embeddings...\n",
      "Evaluating Multimodal embeddings...\n",
      "Evaluation results saved to multimodal_analysis_results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9818/2454320151.py:871: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
      "/tmp/ipykernel_9818/2454320151.py:871: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
      "/tmp/ipykernel_9818/2454320151.py:871: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
      "/tmp/ipykernel_9818/2454320151.py:871: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
      "/tmp/ipykernel_9818/2454320151.py:871: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
      "/tmp/ipykernel_9818/2454320151.py:871: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster separability metrics...\n",
      "Analyzing Clinical embeddings...\n",
      "Analyzing Pathology embeddings...\n",
      "Analyzing Radiology embeddings...\n",
      "Analyzing Molecular embeddings...\n",
      "Analyzing Multimodal embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9818/2454320151.py:1037: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Modality', y='Separation Ratio', data=df_sorted, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing clustering analysis...\n",
      "Analyzing Clinical embeddings...\n",
      "Analyzing Pathology embeddings...\n",
      "Analyzing Radiology embeddings...\n",
      "Analyzing Molecular embeddings...\n",
      "Analyzing Multimodal embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9818/822127376.py:310: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
      "/tmp/ipykernel_9818/822127376.py:310: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
      "/tmp/ipykernel_9818/822127376.py:297: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
      "/tmp/ipykernel_9818/822127376.py:345: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x='Modality', y='Integrated Score',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitative analysis complete. Results saved to multimodal_analysis_results\n",
      "Multimodal integration analysis complete. Results saved to multimodal_analysis_results\n"
     ]
    }
   ],
   "source": [
    "def visualize_multimodal_integration(aligned_data, multimodal_embeddings):\n",
    "    \"\"\"\n",
    "    Visualize the integration of multimodal data using UMAP and perform \n",
    "    quantitative clustering analysis\n",
    "    \"\"\"\n",
    "    print(\"Visualizing multimodal integration and performing quantitative analysis...\")\n",
    "    \n",
    "    # Handle multi-dimensional embeddings by extracting and flattening if needed\n",
    "    clinical_embeddings = []\n",
    "    pathology_embeddings = []\n",
    "    radiology_embeddings = []\n",
    "    molecular_embeddings = []\n",
    "    \n",
    "    for _, row in aligned_data.iterrows():\n",
    "        # Process clinical embedding\n",
    "        emb = row['clinical_embedding']\n",
    "        if emb is None:\n",
    "            clinical_embeddings.append(np.zeros(1024))\n",
    "        elif len(np.array(emb).shape) > 1:\n",
    "            # If multi-dimensional, flatten or take mean\n",
    "            emb_array = np.array(emb)\n",
    "            if len(emb_array.shape) == 2:\n",
    "                # Take mean along first dimension for 2D arrays\n",
    "                clinical_embeddings.append(np.mean(emb_array, axis=0))\n",
    "            else:\n",
    "                # For higher dimensions, flatten to 1D\n",
    "                clinical_embeddings.append(np.array(emb).flatten())\n",
    "        else:\n",
    "            clinical_embeddings.append(np.array(emb))\n",
    "        \n",
    "        # Process pathology embedding\n",
    "        emb = row['pathology_embedding']\n",
    "        if emb is None:\n",
    "            pathology_embeddings.append(np.zeros(1024))\n",
    "        elif len(np.array(emb).shape) > 1:\n",
    "            emb_array = np.array(emb)\n",
    "            if len(emb_array.shape) == 2:\n",
    "                pathology_embeddings.append(np.mean(emb_array, axis=0))\n",
    "            else:\n",
    "                pathology_embeddings.append(np.array(emb).flatten())\n",
    "        else:\n",
    "            pathology_embeddings.append(np.array(emb))\n",
    "        \n",
    "        # Process radiology embedding\n",
    "        emb = row['radiology_embedding']\n",
    "        if emb is None:\n",
    "            radiology_embeddings.append(np.zeros(1000))\n",
    "        elif len(np.array(emb).shape) > 1:\n",
    "            emb_array = np.array(emb)\n",
    "            if len(emb_array.shape) == 2:\n",
    "                radiology_embeddings.append(np.mean(emb_array, axis=0))\n",
    "            else:\n",
    "                radiology_embeddings.append(np.array(emb).flatten())\n",
    "        else:\n",
    "            radiology_embeddings.append(np.array(emb))\n",
    "        \n",
    "        # Process molecular embedding\n",
    "        emb = row['molecular_embedding']\n",
    "        if emb is None:\n",
    "            molecular_embeddings.append(np.zeros(48))\n",
    "        elif len(np.array(emb).shape) > 1:\n",
    "            emb_array = np.array(emb)\n",
    "            if len(emb_array.shape) == 2:\n",
    "                molecular_embeddings.append(np.mean(emb_array, axis=0))\n",
    "            else:\n",
    "                molecular_embeddings.append(np.array(emb).flatten())\n",
    "        else:\n",
    "            molecular_embeddings.append(np.array(emb))\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    clinical_embeddings = np.array(clinical_embeddings)\n",
    "    pathology_embeddings = np.array(pathology_embeddings)\n",
    "    radiology_embeddings = np.array(radiology_embeddings)\n",
    "    molecular_embeddings = np.array(molecular_embeddings)\n",
    "    \n",
    "    print(f\"Clinical embeddings processed shape: {clinical_embeddings.shape}\")\n",
    "    print(f\"Pathology embeddings processed shape: {pathology_embeddings.shape}\")\n",
    "    print(f\"Radiology embeddings processed shape: {radiology_embeddings.shape}\")\n",
    "    print(f\"Molecular embeddings processed shape: {molecular_embeddings.shape}\")\n",
    "    \n",
    "    # Check for and replace NaN values in embeddings\n",
    "    def check_and_fix_nans(arr, name):\n",
    "        nan_count = np.isnan(arr).sum()\n",
    "        if nan_count > 0:\n",
    "            print(f\"WARNING: Found {nan_count} NaN values in {name} embeddings. Replacing with zeros.\")\n",
    "            arr = np.nan_to_num(arr, nan=0.0)\n",
    "        return arr\n",
    "    \n",
    "    clinical_embeddings = check_and_fix_nans(clinical_embeddings, \"clinical\")\n",
    "    pathology_embeddings = check_and_fix_nans(pathology_embeddings, \"pathology\")\n",
    "    radiology_embeddings = check_and_fix_nans(radiology_embeddings, \"radiology\")\n",
    "    molecular_embeddings = check_and_fix_nans(molecular_embeddings, \"molecular\")\n",
    "    multimodal_embeddings = check_and_fix_nans(multimodal_embeddings, \"multimodal\")\n",
    "    \n",
    "    # Apply UMAP to each modality separately - using correct UMAP import\n",
    "    reducer = umap.UMAP(random_state=42)\n",
    "    \n",
    "    # Apply StandardScaler and safely handle UMAP transformation\n",
    "    def safe_umap_transform(data, name):\n",
    "        try:\n",
    "            # Apply StandardScaler, ensuring no NaNs\n",
    "            scaled_data = StandardScaler().fit_transform(data)\n",
    "            scaled_data = np.nan_to_num(scaled_data, nan=0.0)\n",
    "            \n",
    "            # Apply UMAP\n",
    "            transformed = reducer.fit_transform(scaled_data)\n",
    "            return transformed\n",
    "        except Exception as e:\n",
    "            print(f\"Error applying UMAP to {name} embeddings: {e}\")\n",
    "            print(f\"Using random 2D coordinates for {name} embeddings instead\")\n",
    "            return np.random.rand(data.shape[0], 2) * 10\n",
    "    \n",
    "    clinical_umap = safe_umap_transform(clinical_embeddings, \"clinical\")\n",
    "    pathology_umap = safe_umap_transform(pathology_embeddings, \"pathology\")\n",
    "    radiology_umap = safe_umap_transform(radiology_embeddings, \"radiology\")\n",
    "    molecular_umap = safe_umap_transform(molecular_embeddings, \"molecular\")\n",
    "    multimodal_umap = safe_umap_transform(multimodal_embeddings, \"multimodal\")\n",
    "    \n",
    "    # Get unique cancer types\n",
    "    cancer_types = aligned_data['cancer_type'].unique()\n",
    "    print(f\"Cancer types in visualization: {cancer_types}\")\n",
    "    \n",
    "    # Limit to top 8 cancer types by frequency if needed\n",
    "    if len(cancer_types) > 8:\n",
    "        top_cancer_types = aligned_data['cancer_type'].value_counts().nlargest(8).index.tolist()\n",
    "        print(f\"Limiting visualization to top 8 cancer types: {top_cancer_types}\")\n",
    "        \n",
    "        # Create plot_cancer_type for visualization\n",
    "        aligned_data['plot_cancer_type'] = aligned_data['cancer_type'].apply(\n",
    "            lambda x: x if x in top_cancer_types else 'Other'\n",
    "        )\n",
    "        plot_cancer_types = aligned_data['plot_cancer_type'].unique()\n",
    "    else:\n",
    "        aligned_data['plot_cancer_type'] = aligned_data['cancer_type']\n",
    "        plot_cancer_types = cancer_types\n",
    "    \n",
    "    # Define color mapping\n",
    "    colors = sns.color_palette(\"tab10\", len(plot_cancer_types))\n",
    "    color_map = {cancer: color for cancer, color in zip(plot_cancer_types, colors)}\n",
    "    \n",
    "    # Create a 3x2 grid with special layout\n",
    "    fig = plt.figure(figsize=(24, 16), dpi=300)\n",
    "    \n",
    "    # Fix: Create grid spec for 2 rows and 3 columns\n",
    "    gs = plt.GridSpec(2, 3, figure=fig)\n",
    "    \n",
    "    # Create axes for each subplot\n",
    "    ax_clinical = fig.add_subplot(gs[0, 0])       # Row 1, Col 1\n",
    "    ax_pathology = fig.add_subplot(gs[0, 1])      # Row 1, Col 2\n",
    "    ax_molecular = fig.add_subplot(gs[1, 0])      # Row 2, Col 1\n",
    "    ax_radiology = fig.add_subplot(gs[1, 1])      # Row 2, Col 2\n",
    "    ax_multimodal = fig.add_subplot(gs[:, 2])     # Row 1-2, Col 3\n",
    "    \n",
    "    # Plot each modality with its respective subplot\n",
    "    # Clinical\n",
    "    for cancer_type in plot_cancer_types:\n",
    "        mask = aligned_data['plot_cancer_type'] == cancer_type\n",
    "        if sum(mask) > 0:\n",
    "            ax_clinical.scatter(\n",
    "                clinical_umap[mask, 0],\n",
    "                clinical_umap[mask, 1],\n",
    "                c=[color_map[cancer_type]],\n",
    "                alpha=0.7,\n",
    "                s=200,\n",
    "                edgecolor='black'\n",
    "            )\n",
    "    \n",
    "    ax_clinical.set_title('Clinical', fontsize=30, fontweight='bold')\n",
    "    ax_clinical.set_xlabel('UMAP 1', fontsize=20)\n",
    "    ax_clinical.set_ylabel('UMAP 2', fontsize=20)\n",
    "    \n",
    "    # Pathology Report\n",
    "    for cancer_type in plot_cancer_types:\n",
    "        mask = aligned_data['plot_cancer_type'] == cancer_type\n",
    "        if sum(mask) > 0:\n",
    "            ax_pathology.scatter(\n",
    "                pathology_umap[mask, 0],\n",
    "                pathology_umap[mask, 1],\n",
    "                c=[color_map[cancer_type]],\n",
    "                alpha=0.7,\n",
    "                s=200,\n",
    "                edgecolor='black'\n",
    "            )\n",
    "    \n",
    "    ax_pathology.set_title('Pathology Report', fontsize=30, fontweight='bold')\n",
    "    ax_pathology.set_xlabel('UMAP 1', fontsize=20)\n",
    "    ax_pathology.set_ylabel('UMAP 2', fontsize=20)\n",
    "    \n",
    "    # Molecular\n",
    "    for cancer_type in plot_cancer_types:\n",
    "        mask = aligned_data['plot_cancer_type'] == cancer_type\n",
    "        if sum(mask) > 0:\n",
    "            ax_molecular.scatter(\n",
    "                molecular_umap[mask, 0],\n",
    "                molecular_umap[mask, 1],\n",
    "                c=[color_map[cancer_type]],\n",
    "                alpha=0.7,\n",
    "                s=200,\n",
    "                edgecolor='black'\n",
    "            )\n",
    "    \n",
    "    ax_molecular.set_title('Molecular', fontsize=30, fontweight='bold')\n",
    "    ax_molecular.set_xlabel('UMAP 1', fontsize=20)\n",
    "    ax_molecular.set_ylabel('UMAP 2', fontsize=20)\n",
    "    \n",
    "    # Radiology\n",
    "    for cancer_type in plot_cancer_types:\n",
    "        mask = aligned_data['plot_cancer_type'] == cancer_type\n",
    "        if sum(mask) > 0:\n",
    "            ax_radiology.scatter(\n",
    "                radiology_umap[mask, 0],\n",
    "                radiology_umap[mask, 1],\n",
    "                c=[color_map[cancer_type]],\n",
    "                alpha=0.7,\n",
    "                s=200,\n",
    "                edgecolor='black'\n",
    "            )\n",
    "    \n",
    "    ax_radiology.set_title('Radiology', fontsize=30, fontweight='bold')\n",
    "    ax_radiology.set_xlabel('UMAP 1', fontsize=20)\n",
    "    ax_radiology.set_ylabel('UMAP 2', fontsize=20)\n",
    "    \n",
    "    # Multimodal Integration (larger plot at the bottom)\n",
    "    for cancer_type in plot_cancer_types:\n",
    "        mask = aligned_data['plot_cancer_type'] == cancer_type\n",
    "        if sum(mask) > 0:\n",
    "            ax_multimodal.scatter(\n",
    "                multimodal_umap[mask, 0],\n",
    "                multimodal_umap[mask, 1],\n",
    "                c=[color_map[cancer_type]],\n",
    "                alpha=0.7,\n",
    "                s=200,\n",
    "                edgecolor='black',\n",
    "                label=cancer_type\n",
    "            )\n",
    "    \n",
    "    ax_multimodal.set_title('Multimodal Integration', fontsize=30, fontweight='bold')\n",
    "    ax_multimodal.set_xlabel('UMAP 1', fontsize=18)\n",
    "    ax_multimodal.set_ylabel('UMAP 2', fontsize=18)\n",
    "    \n",
    "    # Add legend to the multimodal plot\n",
    "    ax_multimodal.legend(fontsize=16, title=\"Cancer Types\", title_fontsize=18, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/multimodal_umap_visualization.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Also save a text file with dataset information\n",
    "    info_text = (\n",
    "        f\"Total patients: {len(aligned_data)}\\n\\n\"\n",
    "        f\"Cancer type counts:\\n\"\n",
    "        f\"{aligned_data['cancer_type'].value_counts().to_string()}\\n\\n\"\n",
    "        f\"Embedding dimensions:\\n\"\n",
    "        f\"Clinical: {clinical_embeddings.shape[1]}\\n\"\n",
    "        f\"Pathology: {pathology_embeddings.shape[1]}\\n\"\n",
    "        f\"Radiology: {radiology_embeddings.shape[1]}\\n\"\n",
    "        f\"Molecular: {molecular_embeddings.shape[1]}\\n\"\n",
    "        f\"Multimodal: {multimodal_embeddings.shape[1]}\"\n",
    "    )\n",
    "    \n",
    "    with open(f\"{OUTPUT_DIR}/dataset_information.txt\", \"w\") as f:\n",
    "        f.write(info_text)\n",
    "    \n",
    "    print(f\"Visualizations saved to {OUTPUT_DIR}\")\n",
    "    \n",
    "    # ============ NEW CODE FOR QUANTITATIVE ANALYSIS =============\n",
    "    # Collect UMAP embeddings for analysis\n",
    "    umap_embeddings_dict = {\n",
    "        'Clinical': clinical_umap,\n",
    "        'Pathology': pathology_umap,\n",
    "        'Radiology': radiology_umap,\n",
    "        'Molecular': molecular_umap,\n",
    "        'Multimodal': multimodal_umap\n",
    "    }\n",
    "    \n",
    "    # Perform quantitative embedding quality evaluation\n",
    "    metrics_df = evaluate_embedding_quality(aligned_data, umap_embeddings_dict, OUTPUT_DIR)\n",
    "    \n",
    "    # Compute cluster separability metrics\n",
    "    separability_df = compute_cluster_separability(aligned_data, umap_embeddings_dict, OUTPUT_DIR)\n",
    "    \n",
    "    # Perform detailed clustering analysis\n",
    "    clustering_df = perform_clustering_analysis(aligned_data, umap_embeddings_dict, OUTPUT_DIR)\n",
    "    \n",
    "    # Create a summary visualization\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Compare best metrics across modalities\n",
    "    metrics_to_plot = ['Silhouette Score', 'K-means AMI', 'Separation Ratio']\n",
    "    \n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        plt.subplot(3, 1, i+1)\n",
    "        \n",
    "        if metric == 'Separation Ratio':\n",
    "            # Use separability_df for this metric\n",
    "            df_sorted = separability_df.sort_values(by=metric, ascending=False)\n",
    "            ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
    "            \n",
    "            # Add value labels on top of bars\n",
    "            for j, p in enumerate(ax.patches):\n",
    "                ax.annotate(f\"{p.get_height():.3f}\", \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                            ha='center', va='bottom',\n",
    "                            fontsize=10, color='black',\n",
    "                            xytext=(0, 5),\n",
    "                            textcoords='offset points')\n",
    "        else:\n",
    "            # Use metrics_df for other metrics\n",
    "            df_sorted = metrics_df.sort_values(by=metric, ascending=False)\n",
    "            ax = sns.barplot(x='Modality', y=metric, data=df_sorted, palette='viridis')\n",
    "            \n",
    "            # Add value labels on top of bars\n",
    "            for j, p in enumerate(ax.patches):\n",
    "                ax.annotate(f\"{p.get_height():.3f}\", \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                            ha='center', va='bottom',\n",
    "                            fontsize=10, color='black',\n",
    "                            xytext=(0, 5),\n",
    "                            textcoords='offset points')\n",
    "        \n",
    "        plt.title(f\"{metric} Comparison\", fontsize=16)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.xlabel('Modality', fontsize=14)\n",
    "        plt.ylabel(metric, fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'summary_metrics_comparison.png'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create an integrated metric - optional\n",
    "    if all(metric in metrics_df.columns for metric in ['Silhouette Score', 'K-means AMI', 'K-means ARI']):\n",
    "        # Normalize metrics to 0-1 scale\n",
    "        metrics_to_normalize = ['Silhouette Score', 'K-means AMI', 'K-means ARI']\n",
    "        normalized_df = metrics_df.copy()\n",
    "        \n",
    "        for col in metrics_to_normalize:\n",
    "            if normalized_df[col].max() > 0:\n",
    "                normalized_df[col] = normalized_df[col] / normalized_df[col].max()\n",
    "        \n",
    "        # Compute integrated score (mean of normalized metrics)\n",
    "        normalized_df['Integrated Score'] = normalized_df[metrics_to_normalize].mean(axis=1)\n",
    "        \n",
    "        # Plot integrated score\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x='Modality', y='Integrated Score', \n",
    "                     data=normalized_df.sort_values('Integrated Score', ascending=False),\n",
    "                     palette='viridis')\n",
    "        \n",
    "        # Add value labels\n",
    "        for j, p in enumerate(ax.patches):\n",
    "            ax.annotate(f\"{p.get_height():.3f}\", \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=12, color='black',\n",
    "                        xytext=(0, 5),\n",
    "                        textcoords='offset points')\n",
    "        \n",
    "        plt.title('Integrated Clustering Performance Score', fontsize=18)\n",
    "        plt.xlabel('Modality', fontsize=14)\n",
    "        plt.ylabel('Integrated Score (0-1)', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, 'integrated_score_comparison.png'), bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Save integrated metrics to CSV\n",
    "        normalized_df.to_csv(os.path.join(OUTPUT_DIR, 'integrated_metrics.csv'), index=False)\n",
    "    \n",
    "    print(f\"Quantitative analysis complete. Results saved to {OUTPUT_DIR}\")\n",
    "    \n",
    "    return metrics_df, separability_df, clustering_df\n",
    "\n",
    "# Visualize multimodal integration\n",
    "visualize_multimodal_integration(aligned_data, multimodal_embeddings)\n",
    "\n",
    "print(f\"Multimodal integration analysis complete. Results saved to {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HoneyBee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
