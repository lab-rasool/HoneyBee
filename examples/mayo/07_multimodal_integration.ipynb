{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoneyBee Workshop Part 7: Multi-Modal Integration\n",
    "\n",
    "## Overview\n",
    "In this workshop, you'll learn how to:\n",
    "1. Combine embeddings from multiple modalities\n",
    "2. Implement different fusion strategies\n",
    "3. Evaluate multi-modal performance\n",
    "4. Visualize integrated embeddings\n",
    "5. Build end-to-end multi-modal pipelines\n",
    "\n",
    "**Duration**: 30 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Completed Parts 1-6\n",
    "- Understanding of multi-modal learning concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Add HoneyBee to path\n",
    "sys.path.append('/mnt/f/Projects/HoneyBee')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Multi-Modal Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modalities\n",
    "modalities = ['clinical', 'pathology', 'radiology', 'molecular']\n",
    "\n",
    "# Load embeddings (mock data for demonstration)\n",
    "n_samples = 300\n",
    "embeddings = {}\n",
    "\n",
    "# Different embedding dimensions for each modality\n",
    "embedding_dims = {\n",
    "    'clinical': 768,    # BioBERT\n",
    "    'pathology': 1024,  # UNI\n",
    "    'radiology': 2048,  # RadImageNet\n",
    "    'molecular': 512    # Molecular features\n",
    "}\n",
    "\n",
    "# Create correlated mock embeddings\n",
    "base_signal = np.random.randn(n_samples, 50)  # Shared signal\n",
    "patient_ids = [f\"TCGA-{i:04d}\" for i in range(n_samples)]\n",
    "\n",
    "for modality in modalities:\n",
    "    dim = embedding_dims[modality]\n",
    "    \n",
    "    # Project base signal to modality dimension\n",
    "    projection = np.random.randn(50, dim)\n",
    "    modality_signal = base_signal @ projection\n",
    "    \n",
    "    # Add modality-specific noise\n",
    "    noise = np.random.randn(n_samples, dim) * 0.5\n",
    "    \n",
    "    embeddings[modality] = pd.DataFrame(\n",
    "        modality_signal + noise,\n",
    "        index=patient_ids\n",
    "    )\n",
    "    \n",
    "    print(f\"{modality.capitalize()} embeddings: {embeddings[modality].shape}\")\n",
    "\n",
    "# Create labels\n",
    "cancer_types = ['BRCA', 'LUAD', 'KIRC', 'THCA', 'PRAD']\n",
    "labels = pd.Series(\n",
    "    np.random.choice(cancer_types, n_samples),\n",
    "    index=patient_ids,\n",
    "    name='cancer_type'\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal patients: {n_samples}\")\n",
    "print(f\"Cancer types: {labels.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement Fusion Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalFusion:\n",
    "    \"\"\"\n",
    "    Implements various fusion strategies for multi-modal embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def early_fusion(embeddings_dict, method='concat'):\n",
    "        \"\"\"\n",
    "        Early fusion: Combine embeddings before learning\n",
    "        \"\"\"\n",
    "        if method == 'concat':\n",
    "            # Simple concatenation\n",
    "            return pd.concat(embeddings_dict.values(), axis=1)\n",
    "        \n",
    "        elif method == 'kronecker':\n",
    "            # Kronecker product (for 2 modalities)\n",
    "            if len(embeddings_dict) != 2:\n",
    "                raise ValueError(\"Kronecker product requires exactly 2 modalities\")\n",
    "            \n",
    "            emb1, emb2 = list(embeddings_dict.values())\n",
    "            # Reduce dimensions first\n",
    "            pca1 = PCA(n_components=50).fit_transform(emb1)\n",
    "            pca2 = PCA(n_components=50).fit_transform(emb2)\n",
    "            \n",
    "            # Compute Kronecker product for each sample\n",
    "            kron_features = []\n",
    "            for i in range(len(pca1)):\n",
    "                kron = np.kron(pca1[i], pca2[i])\n",
    "                kron_features.append(kron)\n",
    "            \n",
    "            return pd.DataFrame(kron_features, index=emb1.index)\n",
    "    \n",
    "    @staticmethod\n",
    "    def intermediate_fusion(embeddings_dict, n_components=100):\n",
    "        \"\"\"\n",
    "        Intermediate fusion: Project to common space\n",
    "        \"\"\"\n",
    "        # Project each modality to same dimension\n",
    "        projected = {}\n",
    "        \n",
    "        for modality, emb in embeddings_dict.items():\n",
    "            pca = PCA(n_components=n_components)\n",
    "            proj = pca.fit_transform(emb)\n",
    "            projected[modality] = proj\n",
    "        \n",
    "        # Average in common space\n",
    "        fused = np.mean(list(projected.values()), axis=0)\n",
    "        return pd.DataFrame(fused, index=list(embeddings_dict.values())[0].index)\n",
    "    \n",
    "    @staticmethod\n",
    "    def attention_fusion(embeddings_dict, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Attention-based fusion\n",
    "        \"\"\"\n",
    "        # Simple attention mechanism\n",
    "        n_modalities = len(embeddings_dict)\n",
    "        n_samples = len(list(embeddings_dict.values())[0])\n",
    "        \n",
    "        # Learn attention weights (mock for demonstration)\n",
    "        attention_weights = np.random.dirichlet(np.ones(n_modalities), size=n_samples)\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        attention_weights = np.exp(attention_weights / temperature)\n",
    "        attention_weights = attention_weights / attention_weights.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        # Weighted combination\n",
    "        fused_list = []\n",
    "        for i in range(n_samples):\n",
    "            weighted_sum = 0\n",
    "            for j, (modality, emb) in enumerate(embeddings_dict.items()):\n",
    "                # Project to common dimension\n",
    "                pca = PCA(n_components=100)\n",
    "                proj = pca.fit_transform(emb)\n",
    "                weighted_sum += attention_weights[i, j] * proj[i]\n",
    "            fused_list.append(weighted_sum)\n",
    "        \n",
    "        return pd.DataFrame(\n",
    "            fused_list, \n",
    "            index=list(embeddings_dict.values())[0].index\n",
    "        ), attention_weights\n",
    "\n",
    "# Initialize fusion module\n",
    "fusion = MultiModalFusion()\n",
    "print(\"Fusion strategies implemented: early (concat, kronecker), intermediate, attention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Fusion Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different fusion strategies\n",
    "fusion_results = {}\n",
    "\n",
    "# 1. Early fusion - Concatenation\n",
    "print(\"Applying early fusion (concatenation)...\")\n",
    "fused_concat = fusion.early_fusion(embeddings, method='concat')\n",
    "fusion_results['Concatenation'] = fused_concat\n",
    "\n",
    "# 2. Early fusion - Kronecker (using 2 modalities)\n",
    "print(\"Applying early fusion (Kronecker product)...\")\n",
    "two_modalities = {k: v for k, v in list(embeddings.items())[:2]}\n",
    "fused_kronecker = fusion.early_fusion(two_modalities, method='kronecker')\n",
    "fusion_results['Kronecker'] = fused_kronecker\n",
    "\n",
    "# 3. Intermediate fusion\n",
    "print(\"Applying intermediate fusion...\")\n",
    "fused_intermediate = fusion.intermediate_fusion(embeddings)\n",
    "fusion_results['Intermediate'] = fused_intermediate\n",
    "\n",
    "# 4. Attention fusion\n",
    "print(\"Applying attention fusion...\")\n",
    "fused_attention, attention_weights = fusion.attention_fusion(embeddings)\n",
    "fusion_results['Attention'] = fused_attention\n",
    "\n",
    "# Display fusion results\n",
    "for method, fused_data in fusion_results.items():\n",
    "    print(f\"\\n{method} fusion shape: {fused_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Fusion Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each fusion method on classification task\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "performance_results = {}\n",
    "\n",
    "# Also evaluate individual modalities\n",
    "all_embeddings = {**{f'Single-{k}': v for k, v in embeddings.items()}, **fusion_results}\n",
    "\n",
    "for method, emb_data in all_embeddings.items():\n",
    "    print(f\"\\nEvaluating {method}...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = emb_data.values\n",
    "    y = labels.values\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Cross-validation\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    scores = cross_val_score(clf, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    performance_results[method] = {\n",
    "        'mean_accuracy': scores.mean(),\n",
    "        'std_accuracy': scores.std(),\n",
    "        'scores': scores\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "methods = list(performance_results.keys())\n",
    "accuracies = [performance_results[m]['mean_accuracy'] for m in methods]\n",
    "errors = [performance_results[m]['std_accuracy'] * 2 for m in methods]\n",
    "\n",
    "# Color code single vs fusion\n",
    "colors = ['lightblue' if m.startswith('Single') else 'orange' for m in methods]\n",
    "\n",
    "bars = plt.bar(methods, accuracies, yerr=errors, capsize=5, color=colors)\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classification Performance: Single Modality vs Fusion')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 1)\n",
    "plt.axhline(y=np.mean(accuracies), color='red', linestyle='--', alpha=0.5, label='Average')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention weights for different cancer types\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types):\n",
    "    # Get attention weights for this cancer type\n",
    "    cancer_mask = labels == cancer_type\n",
    "    cancer_attention = attention_weights[cancer_mask]\n",
    "    \n",
    "    # Average attention per modality\n",
    "    avg_attention = cancer_attention.mean(axis=0)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    bars = ax.bar(modalities, avg_attention)\n",
    "    ax.set_title(f'{cancer_type} (n={cancer_mask.sum()})')\n",
    "    ax.set_ylabel('Average Attention Weight')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Color highest attention\n",
    "    max_idx = np.argmax(avg_attention)\n",
    "    bars[max_idx].set_color('red')\n",
    "\n",
    "# Remove empty subplot\n",
    "axes[-1].remove()\n",
    "\n",
    "plt.suptitle('Attention Weights by Cancer Type', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap of attention weights\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(attention_weights[:50].T, cmap='YlOrRd', \n",
    "            xticklabels=False, yticklabels=modalities)\n",
    "plt.xlabel('Patients (first 50)')\n",
    "plt.ylabel('Modality')\n",
    "plt.title('Attention Weights Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Integrated Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare t-SNE visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# Select methods to visualize\n",
    "viz_methods = ['Single-clinical', 'Concatenation', 'Intermediate', 'Attention']\n",
    "\n",
    "for idx, method in enumerate(viz_methods):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Get embeddings\n",
    "    if method in all_embeddings:\n",
    "        emb = all_embeddings[method]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Apply t-SNE\n",
    "    print(f\"Computing t-SNE for {method}...\")\n",
    "    \n",
    "    # Reduce dimensions if needed\n",
    "    if emb.shape[1] > 50:\n",
    "        pca = PCA(n_components=50)\n",
    "        emb_reduced = pca.fit_transform(emb)\n",
    "    else:\n",
    "        emb_reduced = emb.values\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    emb_2d = tsne.fit_transform(emb_reduced)\n",
    "    \n",
    "    # Plot\n",
    "    for cancer_type in cancer_types:\n",
    "        mask = labels == cancer_type\n",
    "        ax.scatter(emb_2d[mask, 0], emb_2d[mask, 1], \n",
    "                  label=cancer_type, alpha=0.7, s=50)\n",
    "    \n",
    "    ax.set_title(method)\n",
    "    ax.set_xlabel('t-SNE 1')\n",
    "    ax.set_ylabel('t-SNE 2')\n",
    "    if idx == 0:\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.suptitle('t-SNE Visualization of Different Fusion Methods', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Missing Modality Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate missing modalities\n",
    "missing_rate = 0.2  # 20% missing\n",
    "n_missing = int(n_samples * missing_rate)\n",
    "\n",
    "# Create missing patterns\n",
    "missing_patterns = {\n",
    "    'Missing Pathology': {'pathology': np.random.choice(n_samples, n_missing, replace=False)},\n",
    "    'Missing Radiology': {'radiology': np.random.choice(n_samples, n_missing, replace=False)},\n",
    "    'Missing Both': {\n",
    "        'pathology': np.random.choice(n_samples, n_missing//2, replace=False),\n",
    "        'radiology': np.random.choice(n_samples, n_missing//2, replace=False)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Evaluate performance with missing modalities\n",
    "missing_results = {}\n",
    "\n",
    "for pattern_name, missing_indices in missing_patterns.items():\n",
    "    print(f\"\\nEvaluating {pattern_name}...\")\n",
    "    \n",
    "    # Create copy of embeddings\n",
    "    embeddings_missing = embeddings.copy()\n",
    "    \n",
    "    # Set missing values to zero (simple imputation)\n",
    "    for modality, indices in missing_indices.items():\n",
    "        embeddings_missing[modality].iloc[indices] = 0\n",
    "    \n",
    "    # Apply fusion\n",
    "    fused_missing = fusion.early_fusion(embeddings_missing, method='concat')\n",
    "    \n",
    "    # Evaluate\n",
    "    X = fused_missing.values\n",
    "    y = labels.values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    scores = cross_val_score(clf, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    missing_results[pattern_name] = scores.mean()\n",
    "    print(f\"  Accuracy: {scores.mean():.3f}\")\n",
    "\n",
    "# Add complete data result\n",
    "missing_results['Complete Data'] = performance_results['Concatenation']['mean_accuracy']\n",
    "\n",
    "# Plot missing modality impact\n",
    "plt.figure(figsize=(10, 6))\n",
    "patterns = list(missing_results.keys())\n",
    "accuracies = list(missing_results.values())\n",
    "\n",
    "bars = plt.bar(patterns, accuracies)\n",
    "bars[-1].set_color('green')  # Highlight complete data\n",
    "\n",
    "plt.xlabel('Missing Pattern')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Impact of Missing Modalities on Performance')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Build End-to-End Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalPipeline:\n",
    "    \"\"\"\n",
    "    End-to-end pipeline for multi-modal cancer analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fusion_method='attention'):\n",
    "        self.fusion_method = fusion_method\n",
    "        self.fusion = MultiModalFusion()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def preprocess(self, embeddings_dict):\n",
    "        \"\"\"\n",
    "        Preprocess and fuse embeddings\n",
    "        \"\"\"\n",
    "        # Apply fusion\n",
    "        if self.fusion_method == 'concat':\n",
    "            fused = self.fusion.early_fusion(embeddings_dict, method='concat')\n",
    "        elif self.fusion_method == 'attention':\n",
    "            fused, self.attention_weights = self.fusion.attention_fusion(embeddings_dict)\n",
    "        else:\n",
    "            fused = self.fusion.intermediate_fusion(embeddings_dict)\n",
    "        \n",
    "        return fused\n",
    "    \n",
    "    def fit(self, embeddings_dict, labels):\n",
    "        \"\"\"\n",
    "        Fit the pipeline\n",
    "        \"\"\"\n",
    "        # Preprocess\n",
    "        X = self.preprocess(embeddings_dict)\n",
    "        \n",
    "        # Scale\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Train classifier\n",
    "        self.classifier.fit(X_scaled, labels)\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, embeddings_dict):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Pipeline must be fitted before prediction\")\n",
    "        \n",
    "        # Preprocess\n",
    "        X = self.preprocess(embeddings_dict)\n",
    "        \n",
    "        # Scale\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Predict\n",
    "        return self.classifier.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, embeddings_dict):\n",
    "        \"\"\"\n",
    "        Predict probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Pipeline must be fitted before prediction\")\n",
    "        \n",
    "        X = self.preprocess(embeddings_dict)\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.classifier.predict_proba(X_scaled)\n",
    "\n",
    "# Create and test pipeline\n",
    "pipeline = MultiModalPipeline(fusion_method='attention')\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(n_samples), test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Prepare train/test embeddings\n",
    "train_embeddings = {mod: emb.iloc[train_idx] for mod, emb in embeddings.items()}\n",
    "test_embeddings = {mod: emb.iloc[test_idx] for mod, emb in embeddings.items()}\n",
    "train_labels = labels.iloc[train_idx]\n",
    "test_labels = labels.iloc[test_idx]\n",
    "\n",
    "# Fit pipeline\n",
    "print(\"Training multi-modal pipeline...\")\n",
    "pipeline.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipeline.predict(test_embeddings)\n",
    "probabilities = pipeline.predict_proba(test_embeddings)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"\\nPipeline Performance:\")\n",
    "print(f\"  Test Accuracy: {accuracy:.3f}\")\n",
    "print(f\"  Test F1-score: {f1:.3f}\")\n",
    "\n",
    "# Show example predictions\n",
    "print(\"\\nExample Predictions:\")\n",
    "for i in range(5):\n",
    "    true_label = test_labels.iloc[i]\n",
    "    pred_label = predictions[i]\n",
    "    confidence = probabilities[i].max()\n",
    "    print(f\"  Patient {test_labels.index[i]}: True={true_label}, Pred={pred_label}, Conf={confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Pipeline and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"/mnt/f/Projects/HoneyBee/examples/mayo/outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save pipeline\n",
    "import pickle\n",
    "with open(output_dir / 'multimodal_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "# Save fusion comparison results\n",
    "import json\n",
    "fusion_summary = {\n",
    "    method: {\n",
    "        'mean_accuracy': float(results['mean_accuracy']),\n",
    "        'std_accuracy': float(results['std_accuracy'])\n",
    "    }\n",
    "    for method, results in performance_results.items()\n",
    "}\n",
    "\n",
    "with open(output_dir / 'fusion_comparison.json', 'w') as f:\n",
    "    json.dump(fusion_summary, f, indent=2)\n",
    "\n",
    "# Save attention weights\n",
    "if hasattr(pipeline, 'attention_weights'):\n",
    "    np.save(output_dir / 'attention_weights.npy', pipeline.attention_weights)\n",
    "\n",
    "# Create summary report\n",
    "report = f\"\"\"\n",
    "Multi-Modal Integration Workshop Results\n",
    "======================================\n",
    "\n",
    "Dataset:\n",
    "- Patients: {n_samples}\n",
    "- Modalities: {', '.join(modalities)}\n",
    "- Cancer Types: {', '.join(cancer_types)}\n",
    "\n",
    "Best Fusion Method: {max(fusion_summary, key=lambda x: fusion_summary[x]['mean_accuracy'])}\n",
    "Best Accuracy: {max(fusion_summary[x]['mean_accuracy'] for x in fusion_summary):.3f}\n",
    "\n",
    "Pipeline Performance:\n",
    "- Test Accuracy: {accuracy:.3f}\n",
    "- Test F1-score: {f1:.3f}\n",
    "\n",
    "Missing Modality Impact:\n",
    "- Complete Data: {missing_results['Complete Data']:.3f}\n",
    "- Missing Pathology: {missing_results['Missing Pathology']:.3f}\n",
    "- Missing Radiology: {missing_results['Missing Radiology']:.3f}\n",
    "\"\"\"\n",
    "\n",
    "with open(output_dir / 'multimodal_summary.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"Results saved to: {output_dir}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "In this workshop, you learned to:\n",
    "1. ✅ Implement multiple fusion strategies (early, intermediate, attention)\n",
    "2. ✅ Compare fusion performance across methods\n",
    "3. ✅ Visualize attention weights and integrated embeddings\n",
    "4. ✅ Handle missing modalities gracefully\n",
    "5. ✅ Build end-to-end multi-modal pipelines\n",
    "\n",
    "**Workshop Series Complete!**\n",
    "\n",
    "**Key Takeaways**:\n",
    "- Multi-modal fusion often outperforms single modalities\n",
    "- Attention mechanisms can reveal modality importance\n",
    "- Missing modality handling is crucial for real-world deployment\n",
    "- Different fusion strategies work better for different tasks\n",
    "\n",
    "**Next Steps**:\n",
    "- Try advanced fusion methods (tensor fusion, graph neural networks)\n",
    "- Implement cross-modal learning and translation\n",
    "- Explore interpretability of multi-modal models\n",
    "- Deploy your pipeline on new cancer datasets!\n",
    "\n",
    "**Thank you for completing the HoneyBee Workshop Series!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}