{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoneyBee Workshop Part 4: Downstream Classification Tasks\n",
    "\n",
    "## Overview\n",
    "In this workshop, you'll learn how to:\n",
    "1. Load pre-computed embeddings from HuggingFace or local files\n",
    "2. Perform cancer type classification using embeddings\n",
    "3. Evaluate model performance with proper metrics\n",
    "4. Compare different modalities and fusion strategies\n",
    "\n",
    "**Duration**: 30 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Completed Parts 1-3 or access to pre-computed embeddings\n",
    "- Understanding of basic machine learning concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pre-computed TCGA Embeddings\n",
    "\n",
    "We'll use the TCGA embeddings from HuggingFace or local pre-computed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TCGA embeddings...\n",
      "Dataset available at: https://huggingface.co/datasets/Lab-Rasool/TCGA\n",
      "\n",
      "Loading from local pre-computed embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Load from HuggingFace (if available)\n",
    "print(\"Loading TCGA embeddings...\")\n",
    "print(\"Dataset available at: https://huggingface.co/datasets/Lab-Rasool/TCGA\")\n",
    "\n",
    "# Option 2: Load from local pre-computed embeddings\n",
    "# (Using the shared_data folder from results)\n",
    "local_path = Path(\"/mnt/f/Projects/HoneyBee/results/shared_data/embeddings\")\n",
    "\n",
    "# Load clinical embeddings as example\n",
    "if local_path.exists():\n",
    "    print(\"\\nLoading from local pre-computed embeddings...\")\n",
    "    \n",
    "    # Clinical embeddings\n",
    "    clinical_emb_path = local_path / \"clinical_embeddings.pkl\"\n",
    "    if clinical_emb_path.exists():\n",
    "        clinical_embeddings = pd.read_pickle(clinical_emb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Align embeddings with labels\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m common_patients = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mclinical_embeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m) & \u001b[38;5;28mset\u001b[39m(labels_df[\u001b[33m'\u001b[39m\u001b[33mpatient_id\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCommon patients: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(common_patients)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Filter and align\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "# Align embeddings with labels\n",
    "common_patients = list(set(clinical_embeddings.index) & set(labels_df['patient_id']))\n",
    "print(f\"Common patients: {len(common_patients)}\")\n",
    "\n",
    "# Filter and align\n",
    "X = clinical_embeddings.loc[common_patients]\n",
    "y_df = labels_df[labels_df['patient_id'].isin(common_patients)]\n",
    "y_df = y_df.set_index('patient_id').loc[common_patients]\n",
    "y = y_df['cancer_type']\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {X.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Embeddings with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality for visualization\n",
    "print(\"Computing t-SNE visualization...\")\n",
    "\n",
    "# First apply PCA to speed up t-SNE\n",
    "pca = PCA(n_components=50)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_pca)\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], \n",
    "                     c=y_encoded, cmap='tab10', alpha=0.7)\n",
    "plt.colorbar(scatter, ticks=range(len(le.classes_)), label='Cancer Type')\n",
    "plt.clim(-0.5, len(le.classes_) - 0.5)\n",
    "\n",
    "# Add legend\n",
    "handles = [plt.scatter([], [], c=plt.cm.tab10(i), s=100) \n",
    "           for i in range(len(le.classes_))]\n",
    "plt.legend(handles, le.classes_, title=\"Cancer Type\", \n",
    "          bbox_to_anchor=(1.15, 1), loc='upper left')\n",
    "\n",
    "plt.title('t-SNE Visualization of Clinical Embeddings')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Classification Model\n",
    "\n",
    "We'll use Random Forest as it works well with high-dimensional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Performing 5-fold cross-validation...\")\n",
    "cv_scores = cross_val_score(rf_classifier, X, y_encoded, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nCross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full dataset for detailed evaluation\n",
    "# In practice, use train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1-score (weighted): {f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix - Cancer Type Classification')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "for i, cancer_type in enumerate(le.classes_):\n",
    "    print(f\"{cancer_type}: {per_class_accuracy[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf_classifier.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.bar(range(20), importances[indices[:20]])\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total features: {len(importances)}\")\n",
    "print(f\"Features with importance > 0.001: {(importances > 0.001).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Multi-Modal Classification\n",
    "\n",
    "Compare and combine different modalities for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create embeddings for multiple modalities\n",
    "modalities = ['clinical', 'pathology', 'radiology']\n",
    "modality_embeddings = {}\n",
    "\n",
    "# Create mock embeddings for demonstration\n",
    "for modality in modalities:\n",
    "    if modality == 'clinical':\n",
    "        modality_embeddings[modality] = X  # Use existing clinical\n",
    "    else:\n",
    "        # Mock other modalities\n",
    "        modality_embeddings[modality] = pd.DataFrame(\n",
    "            np.random.randn(len(X), 1024),  # Different embedding sizes\n",
    "            index=X.index\n",
    "        )\n",
    "\n",
    "# Fusion strategies\n",
    "def fuse_embeddings(embeddings_dict, method='concat'):\n",
    "    \"\"\"\n",
    "    Fuse embeddings from multiple modalities\n",
    "    \"\"\"\n",
    "    if method == 'concat':\n",
    "        return pd.concat(embeddings_dict.values(), axis=1)\n",
    "    elif method == 'mean':\n",
    "        # Average embeddings\n",
    "        stacked = np.stack([emb.values for emb in embeddings_dict.values()])\n",
    "        return pd.DataFrame(stacked.mean(axis=0), index=list(embeddings_dict.values())[0].index)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown fusion method: {method}\")\n",
    "\n",
    "# Compare fusion strategies\n",
    "fusion_methods = ['concat', 'mean']\n",
    "fusion_results = {}\n",
    "\n",
    "for method in fusion_methods:\n",
    "    print(f\"\\nTesting {method} fusion...\")\n",
    "    X_fused = fuse_embeddings(modality_embeddings, method)\n",
    "    \n",
    "    # Ensure alignment with labels\n",
    "    X_fused = X_fused.loc[X.index]\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rf_classifier, X_fused, y_encoded, cv=cv, scoring='accuracy')\n",
    "    fusion_results[method] = cv_scores.mean()\n",
    "    \n",
    "    print(f\"{method} fusion accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "methods = list(fusion_results.keys())\n",
    "accuracies = list(fusion_results.values())\n",
    "plt.bar(methods, accuracies)\n",
    "plt.xlabel('Fusion Method')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Multi-Modal Fusion Comparison')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"/mnt/f/Projects/HoneyBee/examples/mayo/outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'accuracy': accuracy,\n",
    "    'f1_score': f1,\n",
    "    'cv_scores': cv_scores.tolist(),\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'classes': le.classes_.tolist(),\n",
    "    'fusion_results': fusion_results\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(output_dir / 'classification_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(rf_classifier, output_dir / 'cancer_classifier.pkl')\n",
    "joblib.dump(le, output_dir / 'label_encoder.pkl')\n",
    "\n",
    "print(f\"Results saved to: {output_dir}\")\n",
    "print(f\"Model saved as: cancer_classifier.pkl\")\n",
    "print(f\"Label encoder saved as: label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "In this workshop, you learned to:\n",
    "1. ✅ Load and prepare embedding data for classification\n",
    "2. ✅ Visualize high-dimensional embeddings with t-SNE\n",
    "3. ✅ Train and evaluate classification models\n",
    "4. ✅ Generate confusion matrices and performance metrics\n",
    "5. ✅ Compare fusion strategies for multi-modal data\n",
    "\n",
    "**Next Workshop**: Part 5 - Retrieval Evaluation\n",
    "\n",
    "**Key Takeaways**:\n",
    "- Pre-trained embeddings capture meaningful cancer-specific patterns\n",
    "- Random Forest works well with high-dimensional embeddings\n",
    "- Multi-modal fusion can improve classification performance\n",
    "- Proper evaluation requires cross-validation and multiple metrics\n",
    "\n",
    "**Exercise**: Try different classifiers (SVM, XGBoost) and embedding combinations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HoneyBee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
